@book{xieBookdownAuthoringBooks,
  title = {Bookdown: {{Authoring Books}} and {{Technical Documents}} with {{R Markdown}}},
  shorttitle = {Bookdown},
  author = {Xie, Yihui},
  url = {https://bookdown.org/yihui/bookdown/},
  urldate = {2019-04-12},
  abstract = {A guide to authoring books with R Markdown, including how to generate figures and tables, and insert cross-references, citations, HTML widgets, and Shiny apps in R Markdown. The book can be exported to HTML, PDF, and e-books (e.g.~EPUB). The book style is customizable. You can easily write and preview the book in RStudio IDE or other editors, and host the book wherever you want (e.g.~bookdown.org).}
}

@book{xieMarkdownDefinitiveGuide,
  title = {R {{Markdown}}: {{The Definitive Guide}}},
  shorttitle = {R {{Markdown}}},
  author = {Xie, Yihui and Allaire, J. J. and Grolemund, Garrett},
  url = {https://bookdown.org/yihui/rmarkdown/},
  urldate = {2019-04-12},
  abstract = {The first official book authored by the core R Markdown developers that provides a comprehensive and accurate reference to the R Markdown ecosystem. With R Markdown, you can easily create reproducible data analysis reports, presentations, dashboards, interactive applications, books, dissertations, websites, and journal articles, while enjoying the simplicity of Markdown and the great power of R and other languages.},
  keywords = {R}
}

@book{grolemundDataScience,
  title = {R for {{Data Science}}},
  author = {Grolemund, Garrett and Wickham, Hadley},
  url = {https://r4ds.had.co.nz/},
  urldate = {2019-04-12},
  abstract = {This book will teach you how to do data science with R: You’ll learn how to get your data into R, get it into the most useful structure, transform it, visualise it and model it. In this book, you will find a practicum of skills for data science. Just as a chemist learns how to clean test tubes and stock a lab, you’ll learn how to clean data and draw plots—and many other things besides. These are the skills that allow data science to happen, and here you will find the best practices for doing each of these things with R. You’ll learn how to use the grammar of graphics, literate programming, and reproducible research to save time. You’ll also learn how to manage cognitive resources to facilitate discoveries when wrangling, visualising, and exploring data.},
  keywords = {Book,R}
}

@book{wickhamAdvanceda,
  title = {Advanced {{R}}},
  author = {Wickham, Hadley},
  edition = {1},
  url = {http://adv-r.had.co.nz/},
  urldate = {2019-04-12}
}

@software{machler2019ProgrammingReproducibleResearch,
  title = {Programming with {{R}} for {{Reproducible Research}}. {{Contribute}} to Mmaechler/{{ProgRRR}} Development by Creating an Account on {{GitHub}}},
  author = {Mächler, Martin},
  date = {2019-04-02T16:26:13Z},
  origdate = {2016-10-12T19:05:46Z},
  url = {https://github.com/mmaechler/ProgRRR},
  urldate = {2019-04-12}
}

@online{guptaHowSearchesFinds,
  title = {How {{R Searches}} and {{Finds Stuff}}},
  author = {Gupta, Suraj},
  url = {https://blog.thatbuthow.com/how-r-searches-and-finds-stuff/},
  urldate = {2019-04-12},
  langid = {american},
  organization = {O Beautiful Code}
}

@book{wickhamAdvanced,
  title = {Advanced {{R}}},
  author = {Wickham, Hadley},
  edition = {2},
  url = {https://adv-r.hadley.nz/},
  urldate = {2019-04-12},
  abstract = {The book is designed primarily for R users who want to improve their programming skills and understanding of the language. It should also be useful for programmers coming to R from other languages, as help you to understand why R works the way it does.}
}

@book{yihui2015DynamicDocumentsKnitr,
  title = {Dynamic {{Documents}} with {{R}} and Knitr},
  author = {Yihui, Xie},
  date = {2015},
  edition = {2},
  publisher = {{Chapman and Hall/CRC}},
  location = {Boca Raton, Florida},
  url = {https://yihui.name/knitr/},
  urldate = {2019-04-12},
  isbn = {978-1-4987-1696-3},
  langid = {american}
}

@article{bolker2009GeneralizedLinearMixed,
  ids = {bolkerGeneralizedLinearMixed2009a},
  title = {Generalized Linear Mixed Models: A Practical Guide for Ecology and Evolution},
  shorttitle = {Generalized Linear Mixed Models},
  author = {Bolker, Ben and Brooks, Mollie E. and Clark, Connie J. and Geange, Shane W. and Poulsen, John R. and Stevens, M. Henry H. and White, Jada-Simone S.},
  date = {2009-03},
  journaltitle = {Trends in Ecology \& Evolution},
  shortjournal = {Trends in Ecology \& Evolution},
  volume = {24},
  number = {3},
  pages = {127--135},
  issn = {01695347},
  doi = {10.1016/j.tree.2008.10.008},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0169534709000196},
  urldate = {2020-04-09},
  langid = {english},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\B\Bolker et al_2009_Generalized linear mixed models.pdf}
}

@book{mrode2005LinearModelsPrediction,
  title = {Linear Models for the Prediction of Animal Breeding Values},
  author = {Mrode, R. A. and Thompson, Robin},
  date = {2005},
  edition = {2nd ed},
  publisher = {CABI Pub},
  location = {Wallingford, UK ; Cambridge, MA},
  isbn = {978-0-85199-000-2},
  langid = {english},
  pagetotal = {344},
  keywords = {Breeding Mathematical models,Breeding Statistical methods,Genetics Mathematical models,Genetics Statistical methods,Livestock},
  annotation = {OCLC: ocm56509471},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\M\Mrode_Thompson_2005_Linear models for the prediction of animal breeding values.pdf}
}

@book{falconer1996IntroductionQuantitativeGenetics,
  title = {Introduction to Quantitative Genetics},
  author = {Falconer, Douglas S. and Mackay, Trudy F. C.},
  date = {1996},
  edition = {4. ed.},
  publisher = {Pearson, Prentice Hall},
  location = {Harlow},
  isbn = {978-0-582-24302-6},
  langid = {english},
  pagetotal = {464},
  annotation = {OCLC: 552422435},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\F\Falconer_Mackay_1996_Introduction to quantitative genetics.pdf}
}

@article{bates2015FittingLinearMixedEffects,
  title = {Fitting {{Linear Mixed-Effects Models Using}} Lme4},
  author = {Bates, Douglas and Mächler, Martin and Bolker, Ben and Walker, Steven},
  date = {2015},
  journaltitle = {Journal of Statistical Software},
  shortjournal = {J. Stat. Soft.},
  volume = {67},
  number = {1},
  issn = {1548-7660},
  doi = {10.18637/jss.v067.i01},
  url = {http://www.jstatsoft.org/v67/i01/},
  urldate = {2020-04-10},
  abstract = {Maximum likelihood or restricted maximum likelihood (REML) estimates of the parameters in linear mixed-effects models can be determined using the lmer function in the lme4 package for R. As for most model-fitting functions in R, the model is described in an lmer call by a formula, in this case including both fixed- and random-effects terms. The formula and data together determine a numerical representation of the model from which the profiled deviance or the profiled REML criterion can be evaluated as a function of some of the model parameters. The appropriate criterion is optimized, using one of the constrained optimization functions in R, to provide the parameter estimates. We describe the structure of the model, the steps in evaluating the profiled deviance or REML criterion, and the structure of classes or types that represents such a model. Sufficient detail is included to allow specialization of these structures by users who wish to write functions to fit specialized linear mixed models, such as models incorporating pedigrees or smoothing splines, that are not easily expressible in the formula language used by lmer.},
  langid = {english},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\B\Bates et al_2015_Fitting Linear Mixed-Effects Models Using lme4.pdf}
}

@article{hill2014ApplicationsPopulationGenetics,
  ids = {hillApplicationsPopulationGenetics2014},
  title = {Applications of {{Population Genetics}} to {{Animal Breeding}}, from {{Wright}}, {{Fisher}} and {{Lush}} to {{Genomic Prediction}}},
  author = {Hill, William G.},
  date = {2014-01},
  journaltitle = {Genetics},
  shortjournal = {Genetics},
  volume = {196},
  number = {1},
  eprint = {24395822},
  eprinttype = {pmid},
  pages = {1--16},
  publisher = {Genetics},
  issn = {0016-6731},
  doi = {10.1534/genetics.112.147850},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3872177/},
  urldate = {2020-08-09},
  abstract = {Although animal breeding was practiced long before the science of genetics and the relevant disciplines of population and quantitative genetics were known, breeding programs have mainly relied on simply selecting and mating the best individuals on their own or relatives’ performance. This is based on sound quantitative genetic principles, developed and expounded by Lush, who attributed much of his understanding to Wright, and formalized in Fisher’s infinitesimal model. Analysis at the level of individual loci and gene frequency distributions has had relatively little impact. Now with access to genomic data, a revolution in which molecular information is being used to enhance response with “genomic selection” is occurring. The predictions of breeding value still utilize multiple loci throughout the genome and, indeed, are largely compatible with additive and specifically infinitesimal model assumptions. I discuss some of the history and genetic issues as applied to the science of livestock improvement, which has had and continues to have major spin-offs into ideas and applications in other areas.},
  pmcid = {PMC3872177},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\H\Hill_2014_Applications of Population Genetics to Animal Breeding, from Wright, Fisher and.pdf}
}

@unpublished{bates2018ComputationalMethodsMixed,
  title = {Computational Methods for Mixed Models},
  author = {Bates, Douglas},
  date = {2018},
  abstract = {The lme4 package provides R functions to fit and analyze several different types of mixed-effects models, including linear mixed models, generalized linear mixed models and nonlinear mixed models. In this vignette we describe the formulation of these models and the computational approach used to evaluate or approximate the log-likelihood of a model/data/parameter value combination.},
  howpublished = {Unpubished (http://cran.fhcrc.org/web/packages/lme4/vignettes/Theory.pdf)},
  langid = {english},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\B\Bates_2018_Computational methods for mixed models.pdf}
}

@book{mrode2014LinearModelsPrediction,
  title = {Linear Models for the Prediction of Animal Breeding Values},
  author = {Mrode, R. A.},
  date = {2014},
  edition = {3rd ed},
  publisher = {CABI},
  location = {Boston, MA},
  isbn = {978-1-84593-981-6 978-1-78064-391-5},
  langid = {english},
  keywords = {Breeding Mathematical models,Breeding Statistical methods,Genetics Mathematical models,Genetics Statistical methods,Livestock},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\M\Mrode_2014_Linear models for the prediction of animal breeding values.pdf}
}

@article{gianola2015OneHundredYears,
  title = {One {{Hundred Years}} of {{Statistical Developments}} in {{Animal Breeding}}},
  author = {Gianola, Daniel and Rosa, Guilherme J.M.},
  date = {2015-02-16},
  journaltitle = {Annual Review of Animal Biosciences},
  shortjournal = {Annu. Rev. Anim. Biosci.},
  volume = {3},
  number = {1},
  pages = {19--56},
  publisher = {Annual Reviews},
  issn = {2165-8102},
  doi = {10.1146/annurev-animal-022114-110733},
  url = {https://www.annualreviews.org/doi/10.1146/annurev-animal-022114-110733},
  urldate = {2020-05-09},
  abstract = {Statistical methodology has played a key role in scientific animal breeding. Approximately one hundred years of statistical developments in animal breeding are reviewed. Some of the scientific foundations of the field are discussed, and many milestones are examined from historical and critical perspectives. The review concludes with a discussion of some future challenges and opportunities arising from the massive amount of data generated by livestock, plant, and human genome projects.},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\G\Gianola_Rosa_2015_One Hundred Years of Statistical Developments in Animal Breeding.pdf}
}

@article{charlesworth2018CenturyVariance,
  title = {A Century of Variance},
  author = {Charlesworth, Brian and Edwards, Anthony W. F.},
  date = {2018},
  journaltitle = {Significance},
  volume = {15},
  number = {4},
  pages = {20--25},
  issn = {1740-9713},
  doi = {10.1111/j.1740-9713.2018.01170.x},
  url = {https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/j.1740-9713.2018.01170.x},
  urldate = {2020-05-11},
  abstract = {Brian Charlesworth and Anthony W. F. Edwards mark the 100th anniversary of a paper by R. A. Fisher, which introduced the statistical term “variance”. What followed was a whole new field of statistical analysis},
  langid = {english},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\C\Charlesworth_Edwards_2018_A century of variance.pdf}
}

@book{lynch1998GeneticsAnalysisQuantitative,
  title = {Genetics and Analysis of Quantitative Traits},
  author = {Lynch, Michael and Walsh, Bruce},
  date = {1998},
  publisher = {Sinauer Assoc},
  location = {Sunderland, Mass},
  isbn = {978-0-87893-481-2},
  pagetotal = {980},
  annotation = {OCLC: 246986840},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\L\Lynch_Walsh_1998_Genetics and analysis of quantitative traits.pdf}
}

@book{henderson1984ApplicationsLinearModels,
  title = {Applications of Linear Models in Animal Breeding},
  author = {Henderson, Charles R.},
  date = {1984},
  volume = {462},
  publisher = {University of Guelph Guelph},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\H\Henderson_1984_Applications of linear models in animal breeding.pdf}
}

@article{burkner2017BrmsPackageBayesian,
  title = {Brms: {{An R Package}} for {{Bayesian Multilevel Models Using Stan}}},
  shorttitle = {Brms},
  author = {Bürkner, Paul-Christian},
  date = {2017-08-29},
  journaltitle = {Journal of Statistical Software},
  volume = {80},
  number = {1},
  pages = {1--28},
  issn = {1548-7660},
  doi = {10.18637/jss.v080.i01},
  url = {https://www.jstatsoft.org/index.php/jss/article/view/v080i01},
  urldate = {2020-07-15},
  issue = {1},
  langid = {english},
  keywords = {Bayesian inference,MCMC,multilevel model,ordinal data,R,Stan},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\B\Bürkner_2017_brms.pdf}
}

@unpublished{betancourt2018ConceptualIntroductionHamiltonian,
  title = {A {{Conceptual Introduction}} to {{Hamiltonian Monte Carlo}}},
  author = {Betancourt, Michael},
  date = {2018-07-15},
  eprint = {1701.02434},
  eprinttype = {arXiv},
  eprintclass = {stat},
  url = {http://arxiv.org/abs/1701.02434},
  urldate = {2020-07-25},
  abstract = {Hamiltonian Monte Carlo has proven a remarkable empirical success, but only recently have we begun to develop a rigorous understanding of why it performs so well on difficult problems and how it is best applied in practice. Unfortunately, that understanding is confined within the mathematics of differential geometry which has limited its dissemination, especially to the applied communities for which it is particularly important. In this review I provide a comprehensive conceptual account of these theoretical foundations, focusing on developing a principled intuition behind the method and its optimal implementations rather of any exhaustive rigor. Whether a practitioner or a statistician, the dedicated reader will acquire a solid grasp of how Hamiltonian Monte Carlo works, when it succeeds, and, perhaps most importantly, when it fails.},
  keywords = {Statistics - Methodology},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\B\Betancourt_2018_A Conceptual Introduction to Hamiltonian Monte Carlo.pdf}
}

@article{meuwissen2001PredictionTotalGenetic,
  title = {Prediction of {{Total Genetic Value Using Genome-Wide Dense Marker Maps}}},
  author = {Meuwissen, T. H. E. and Hayes, B. J. and Goddard, M. E.},
  date = {2001-04-01},
  journaltitle = {Genetics},
  volume = {157},
  number = {4},
  eprint = {11290733},
  eprinttype = {pmid},
  pages = {1819--1829},
  publisher = {Genetics},
  issn = {0016-6731, 1943-2631},
  url = {https://www.genetics.org/content/157/4/1819},
  urldate = {2020-08-09},
  abstract = {Recent advances in molecular genetic techniques will make dense marker maps available and genotyping many individuals for these markers feasible. Here we attempted to estimate the effects of ∼50,000 marker haplotypes simultaneously from a limited number of phenotypic records. A genome of 1000 cM was simulated with a marker spacing of 1 cM. The markers surrounding every 1-cM region were combined into marker haplotypes. Due to finite population size (Ne = 100), the marker haplotypes were in linkage disequilibrium with the QTL located between the markers. Using least squares, all haplotype effects could not be estimated simultaneously. When only the biggest effects were included, they were overestimated and the accuracy of predicting genetic values of the offspring of the recorded animals was only 0.32. Best linear unbiased prediction of haplotype effects assumed equal variances associated to each 1-cM chromosomal segment, which yielded an accuracy of 0.73, although this assumption was far from true. Bayesian methods that assumed a prior distribution of the variance associated with each chromosome segment increased this accuracy to 0.85, even when the prior was not correct. It was concluded that selection on genetic values predicted from markers could substantially increase the rate of genetic gain in animals and plants, especially if combined with reproductive techniques to shorten the generation interval.},
  langid = {english},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\M\Meuwissen et al_2001_Prediction of Total Genetic Value Using Genome-Wide Dense Marker Maps.pdf}
}

@article{burkner2019OrdinalRegressionModels,
  title = {Ordinal {{Regression Models}} in {{Psychology}}: {{A Tutorial}}},
  shorttitle = {Ordinal {{Regression Models}} in {{Psychology}}},
  author = {Bürkner, Paul-Christian and Vuorre, Matti},
  date = {2019},
  journaltitle = {Advances in Methods and Practices in Psychological Science},
  shortjournal = {Advances in Methods and Practices in Psychological Science},
  volume = {2},
  number = {1},
  pages = {77--101},
  issn = {2515-2459, 2515-2467},
  doi = {10.1177/2515245918823199},
  url = {http://journals.sagepub.com/doi/10.1177/2515245918823199},
  urldate = {2020-08-23},
  langid = {english},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\B\Bürkner_Vuorre_2019_Ordinal Regression Models in Psychology.pdf}
}

@article{chakraborti2007ConfidenceIntervalEstimation,
  title = {Confidence {{Interval Estimation}} of a {{Normal Percentile}}},
  author = {Chakraborti, S. and Li, J.},
  date = {2007-11-01},
  journaltitle = {The American Statistician},
  volume = {61},
  number = {4},
  pages = {331--336},
  publisher = {Taylor \& Francis},
  issn = {0003-1305},
  doi = {10.1198/000313007X244457},
  url = {https://doi.org/10.1198/000313007X244457},
  urldate = {2021-01-06},
  abstract = {Percentiles (or quantiles) are ubiquitous in descriptive as well as inferential analyses of data. Many applications in practice involve percentiles from the normal distribution. We consider confidence interval estimation of a normal distribution percentile and study several methods including the ones based on the maximum likelihood and the approximate normality of sample percentiles, that is, order statistics. The nonparametric confidence interval, based on the sign test, is included as a benchmark as it is a simple method and is valid for all continuous distributions. A Bayesian posterior predictive interval is also considered. The performance of the methods is examined in a simulation study via coverage and expected length. Summary and recommendations are given.},
  keywords = {Asymptotic normality,Bayesian interval,Conditioning method,Coverage,Expected length,Order statistic,Quantile,Simulation,Vague prior},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\C\Chakraborti_Li_2007_Confidence Interval Estimation of a Normal Percentile.pdf}
}

@book{lawless2003StatisticalModelsMethods,
  title = {Statistical Models and Methods for Lifetime Data},
  author = {Lawless, Jerald F.},
  date = {2003},
  series = {Wiley Series in Probability and Statistics},
  edition = {2nd ed},
  publisher = {Wiley-Interscience},
  location = {Hoboken, N.J},
  isbn = {978-0-471-37215-8},
  langid = {english},
  pagetotal = {630},
  keywords = {Failure time data analysis,Survival analysis (Biometry)},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\L\Lawless_2003_Statistical models and methods for lifetime data.pdf}
}

@book{wood2017GeneralizedAdditiveModels,
  title = {Generalized {{Additive Models}}: {{An Introduction}} with {{R}}},
  author = {Wood, Simon N},
  date = {2017},
  edition = {2},
  publisher = {CRC Press},
  url = {https://doi.org/10.1201/9781315370279},
  langid = {english},
  keywords = {Book,Stat},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\W\Wood_2017_Generalized Additive Models.pdf}
}

@book{held2013MedizinischeStatistikKonzepte,
  title = {Medizinische Statistik : Konzepte, Methoden, Anwendungen},
  shorttitle = {Medizinische Statistik},
  author = {Held, Leonhard and Rufibach, Kaspar and Seifert, Burkhardt},
  date = {2013},
  journaltitle = {Held, Leonhard; Rufibach, Kaspar; Seifert, Burkhardt  (2013). Medizinische Statistik : Konzepte, Methoden, Anwendungen.  München: Pearson.},
  publisher = {Pearson},
  location = {München},
  url = {https://www.zora.uzh.ch/id/eprint/86186/},
  urldate = {2021-01-21},
  isbn = {978-3-86894-100-5},
  langid = {deu},
  pagetotal = {442},
  keywords = {Book,Stat}
}

@article{ruscio2008ConstructingConfidenceIntervals,
  title = {Constructing {{Confidence Intervals}} for {{Spearman}}’s {{Rank Correlation}} with {{Ordinal Data}}: {{A Simulation Study Comparing Analytic}} and {{Bootstrap Methods}}},
  shorttitle = {Constructing {{Confidence Intervals}} for {{Spearman}}’s {{Rank Correlation}} with {{Ordinal Data}}},
  author = {Ruscio, John},
  date = {2008-11-01},
  journaltitle = {Journal of Modern Applied Statistical Methods},
  volume = {7},
  number = {2},
  issn = {1538 - 9472},
  doi = {10.22237/jmasm/1225512360},
  url = {https://digitalcommons.wayne.edu/jmasm/vol7/iss2/7},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\R\Ruscio_2008_Constructing Confidence Intervals for Spearman’s Rank Correlation with Ordinal.pdf}
}

@article{bonett2000SampleSizeRequirements,
  title = {Sample Size Requirements for Estimating Pearson, Kendall and Spearman Correlations},
  author = {Bonett, Douglas G. and Wright, Thomas A.},
  date = {2000-03-01},
  journaltitle = {Psychometrika},
  shortjournal = {Psychometrika},
  volume = {65},
  number = {1},
  pages = {23--28},
  issn = {1860-0980},
  doi = {10.1007/BF02294183},
  url = {https://doi.org/10.1007/BF02294183},
  urldate = {2021-01-22},
  abstract = {Interval estimates of the Pearson, Kendall tau-a and Spearman correlations are reviewed and an improved standard error for the Spearman correlation is proposed. The sample size required to yield a confidence interval having the desired width is examined. A two-stage approximation to the sample size requirement is shown to give accurate results.},
  langid = {english},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\B\Bonett_Wright_2000_Sample size requirements for estimating pearson, kendall and spearman.pdf}
}

@article{bishara2017ConfidenceIntervalsCorrelations,
  title = {Confidence Intervals for Correlations When Data Are Not Normal},
  author = {Bishara, Anthony J. and Hittner, James B.},
  date = {2017-02-01},
  journaltitle = {Behavior Research Methods},
  shortjournal = {Behav Res},
  volume = {49},
  number = {1},
  pages = {294--309},
  issn = {1554-3528},
  doi = {10.3758/s13428-016-0702-8},
  url = {https://doi.org/10.3758/s13428-016-0702-8},
  urldate = {2021-01-23},
  abstract = {With nonnormal data, the typical confidence interval of the correlation (Fisher z') may be inaccurate. The literature has been unclear as to which of several alternative methods should be used instead, and how extreme a violation of normality is needed to justify an alternative. Through Monte Carlo simulation, 11 confidence interval methods were compared, including Fisher z', two Spearman rank-order methods, the Box–Cox transformation, rank-based inverse normal (RIN) transformation, and various bootstrap methods. Nonnormality often distorted the Fisher z' confidence interval—for example, leading to a 95~\% confidence interval that had actual coverage as low as 68~\%. Increasing the sample size sometimes worsened this problem. Inaccurate Fisher z' intervals could be predicted by a sample kurtosis of at least 2, an absolute sample skewness of at least 1, or significant violations of normality hypothesis tests. Only the Spearman rank-order and RIN transformation methods were universally robust to nonnormality. Among the bootstrap methods, an observed imposed bootstrap came closest to accurate coverage, though it often resulted in an overly long interval. The results suggest that sample nonnormality can justify avoidance of the Fisher z' interval in favor of a more robust alternative. R code for the relevant methods is provided in supplementary materials.},
  langid = {english},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\B\Bishara_Hittner_2017_Confidence intervals for correlations when data are not normal.pdf}
}

@article{best1975Algorithm89Upper,
  title = {Algorithm {{AS}} 89: {{The Upper Tail Probabilities}} of {{Spearman}}'s {{Rho}}},
  shorttitle = {Algorithm {{AS}} 89},
  author = {Best, D. J. and Roberts, D. E.},
  date = {1975},
  journaltitle = {Journal of the Royal Statistical Society. Series C (Applied Statistics)},
  volume = {24},
  number = {3},
  eprint = {2347111},
  eprinttype = {jstor},
  pages = {377--379},
  publisher = {[Wiley, Royal Statistical Society]},
  issn = {0035-9254},
  doi = {10.2307/2347111},
  url = {https://www.jstor.org/stable/2347111},
  urldate = {2021-01-24}
}

@article{goeman2014MultipleHypothesisTesting,
  title = {Multiple Hypothesis Testing in Genomics},
  author = {Goeman, Jelle J. and Solari, Aldo},
  date = {2014},
  journaltitle = {Statistics in Medicine},
  volume = {33},
  number = {11},
  pages = {1946--1978},
  issn = {1097-0258},
  doi = {10.1002/sim.6082},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.6082},
  urldate = {2021-01-27},
  abstract = {This paper presents an overview of the current state of the art in multiple testing in genomics data from a user's perspective. We describe methods for familywise error control, false discovery rate control and false discovery proportion estimation and confidence, both conceptually and practically, and explain when to use which type of error rate. We elaborate on the assumptions underlying the methods and discuss pitfalls in the interpretation of results. In our discussion, we take into account the exploratory nature of genomics experiments, looking at selection of genes before or after testing, and at the role of validation experiments. Copyright © 2014 John Wiley \& Sons, Ltd.},
  langid = {english},
  keywords = {Bonferroni,false discovery proportion,false discovery rate,familywise error rate,FDR},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\G\Goeman_Solari_2014_Multiple hypothesis testing in genomics.pdf}
}

@article{ialongo2019ConfidenceIntervalQuantiles,
  title = {Confidence Interval for Quantiles and Percentiles},
  author = {Ialongo, Cristiano},
  date = {2019-02-15},
  journaltitle = {Biochemia Medica},
  shortjournal = {Biochem Med (Zagreb)},
  volume = {29},
  number = {1},
  eprint = {30591808},
  eprinttype = {pmid},
  issn = {1330-0962},
  doi = {10.11613/BM.2019.010101},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6294150/},
  urldate = {2021-01-29},
  abstract = {Quantiles and percentiles represent useful statistical tools for describing the distribution of results and deriving reference intervals and performance specification in laboratory medicine. They are commonly intended as the sample estimate of a population parameter and therefore they need to be presented with a confidence interval (CI). In this work we discuss three methods to estimate CI on quantiles and percentiles using parametric, nonparametric and resampling (bootstrap) approaches. The result of our numerical simulations is that parametric methods are always more accurate regardless of sample size when the procedure is appropriate for the distribution of results for both extreme (2.5th and 97.5th) and central (25th, 50th and 75th) percentiles and corresponding quantiles. We also show that both nonparametric and bootstrap methods suit well the CI of central percentiles that are used to derive performance specifications through quality indicators of laboratory processes whose underlying distribution is unknown.},
  pmcid = {PMC6294150},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\I\Ialongo_2019_Confidence interval for quantiles and percentiles.pdf}
}

@article{hyndman1996SampleQuantilesStatistical,
  title = {Sample {{Quantiles}} in {{Statistical Packages}}},
  author = {Hyndman, Rob J. and Fan, Yanan},
  date = {1996},
  journaltitle = {The American Statistician},
  volume = {50},
  number = {4},
  eprint = {2684934},
  eprinttype = {jstor},
  pages = {361--365},
  publisher = {[American Statistical Association, Taylor \& Francis, Ltd.]},
  issn = {0003-1305},
  doi = {10.2307/2684934},
  url = {https://www.jstor.org/stable/2684934},
  urldate = {2021-01-29},
  abstract = {There are a large number of different definitions used for sample quantiles in statistical computer packages. Often within the same package one definition will be used to compute a quantile explicitly, while other definitions may be used when producing a boxplot, a probability plot, or a QQ plot. We compare the most commonly implemented sample quantile definitions by writing them in a common notation and investigating their motivation and some of their properties. We argue that there is a need to adopt a standard definition for sample quantiles so that the same answers are produced by different packages and within each package. We conclude by recommending that the median-unbiased estimator be used because it has most of the desirable properties of a quantile estimator and can be defined independently of the underlying distribution.},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\H\Hyndman_Fan_1996_Sample Quantiles in Statistical Packages.pdf}
}

@article{ramalho2011AlternativeEstimatingTesting,
  title = {Alternative {{Estimating}} and {{Testing Empirical Strategies}} for {{Fractional Regression Models}}},
  author = {Ramalho, Esmeralda A. and Ramalho, Joaquim J. S. and Murteira, José M. R.},
  date = {2011},
  journaltitle = {Journal of Economic Surveys},
  volume = {25},
  number = {1},
  pages = {19--68},
  issn = {1467-6419},
  doi = {10.1111/j.1467-6419.2009.00602.x},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-6419.2009.00602.x},
  urldate = {2021-02-05},
  abstract = {In many economic settings, the variable of interest is often a fraction or a proportion, being defined only on the unit interval. The bounded nature of such variables and, in some cases, the possibility of nontrivial probability mass accumulating at one or both boundaries raise some interesting estimation and inference issues. In this paper we (i) provide a comprehensive survey of the main alternative models and estimation methods suitable to deal with fractional response variables, (ii) propose a full testing methodology to assess the validity of the assumptions required by each alternative estimator and (iii) examine the finite-sample properties of most of the estimators and tests discussed through an extensive Monte Carlo study. An application concerning corporate capital structure choices is also provided.},
  langid = {english},
  keywords = {Conditional mean tests,Fractional regression models,Non-nested hypotheses,Two-part models,Zero outcomes},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\R\Ramalho et al_2011_Alternative Estimating and Testing Empirical Strategies for Fractional.pdf}
}

@book{fahrmeir2013RegressionModelsMethods,
  title = {Regression: {{Models}}, {{Methods}} and {{Applications}}},
  shorttitle = {Regression},
  author = {Fahrmeir, Ludwig and Kneib, Thomas and Lang, Stefan and Marx, Brian},
  date = {2013},
  publisher = {Springer-Verlag},
  location = {Berlin Heidelberg},
  doi = {10.1007/978-3-642-34333-9},
  url = {https://www.springer.com/de/book/9783642343322},
  urldate = {2021-02-09},
  abstract = {The aim of this book is an applied and unified introduction into parametric, non- and semiparametric regression that closes the gap between theory and application. The most important models and methods in regression are presented on a solid formal basis, and their appropriate application is shown through many real data examples and case studies. Availability of (user-friendly) software has been a major criterion for the methods selected and presented. Thus, the book primarily targets an audience that includes students, teachers and practitioners in social, economic, and life sciences, as well as students and teachers in statistics programs, and mathematicians and computer scientists with interests in statistical modeling and data analysis. It is written on an intermediate mathematical level and assumes only knowledge of basic probability, calculus, and statistics. The most important definitions and statements are concisely summarized in boxes. Two appendices describe required matrix algebra, as well as elements of probability calculus and statistical inference.},
  isbn = {978-3-642-34332-2},
  langid = {english},
  keywords = {Book,Stat},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\F\Fahrmeir et al_2013_Regression.pdf}
}

@article{giancristofaro2019RegressionAnalysisCompositional,
  title = {Regression Analysis with Compositional Data Using Orthogonal Log-Ratio Coordinates},
  author = {Giancristofaro, R. Arboretti and Gastaldi, M. and Martinello, L. and Meneguzzer, C.},
  date = {2019-11-12},
  journaltitle = {Communications in Statistics - Simulation and Computation},
  volume = {0},
  number = {0},
  pages = {1--14},
  publisher = {Taylor \& Francis},
  issn = {0361-0918},
  doi = {10.1080/03610918.2019.1691224},
  url = {https://doi.org/10.1080/03610918.2019.1691224},
  urldate = {2021-03-01},
  abstract = {Compositional data frequently arise when data refer to components which are proportions or fractions of a whole. Within the log-ratio approach, the analysis of compositional data can be conducted in terms of log-ratio transformations of components. These transformations make it possible to overcome the problem of the constant-sum constraint, making standard statistical methods applicable. In the present work, the log-ratio approach based on orthogonal log-ratio coordinates is adopted to show how it can lead to considerable improvements in the interpretation of the results of regression modeling with compositional data, both as explanatory or response variables. In order to demonstrate its practical usefulness, the methodology presented in this paper is applied to the analysis of air pollution produced by vehicles traveling through road intersections, with a specific focus on the effect of the type of traffic control (traffic signal vs. roundabout) on CO2 emissions.},
  keywords = {62J05,62J12,Air pollution,Compositional data,Regression models,Traffic control},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\G\Giancristofaro et al_2019_Regression analysis with compositional data using orthogonal log-ratio.pdf}
}

@article{papke1996EconometricMethodsFractional,
  title = {Econometric Methods for Fractional Response Variables with an Application to 401(k) Plan Participation Rates},
  author = {Papke, Leslie E. and Wooldridge, Jeffrey M.},
  date = {1996},
  journaltitle = {Journal of Applied Econometrics},
  volume = {11},
  number = {6},
  pages = {619--632},
  issn = {1099-1255},
  doi = {10.1002/(SICI)1099-1255(199611)11:6<619::AID-JAE418>3.0.CO;2-1},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/%28SICI%291099-1255%28199611%2911%3A6%3C619%3A%3AAID-JAE418%3E3.0.CO%3B2-1},
  urldate = {2021-03-01},
  abstract = {We develop attractive functional forms and simple quasi-likelihood estimation methods for regression models with a fractional dependent variable. Compared with log-odds type procedures, there is no difficulty in recovering the regression function for the fractional variable, and there is no need to use ad hoc transformations to handle data at the extreme values of zero and one. We also offer some new, robust specification tests by nesting the logit or probit function in a more general functional form. We apply these methods to a data set of employee participation rates in 401(k) pension plans.},
  langid = {english},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\P\Papke_Wooldridge_1996_Econometric methods for fractional response variables with an application to.pdf}
}

@article{muller2018InterpretationCompositionalRegression,
  title = {Interpretation of {{Compositional Regression}} with {{Application}} to {{Time Budget Analysis}}},
  author = {Muller, Ivo and Hron, Karel and Fiserova, Eva and Smahaj, Jan and Cakirpaloglu, Panajotis and Vancakova, Jana},
  date = {2018-02-02},
  journaltitle = {Austrian Journal of Statistics},
  shortjournal = {AJS},
  volume = {47},
  number = {2},
  pages = {3--19},
  issn = {1026-597X},
  doi = {10.17713/ajs.v47i2.652},
  url = {https://www.ajs.or.at/index.php/ajs/article/view/vol47-2-1},
  urldate = {2021-03-01},
  issue = {2},
  langid = {english},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\M\Muller et al_2018_Interpretation of Compositional Regression with Application to Time Budget.pdf}
}

@incollection{ramalho2019ChapterModelingFractional,
  title = {Chapter 8 - {{Modeling}} Fractional Responses Using {{R}}},
  booktitle = {Handbook of {{Statistics}}},
  author = {Ramalho, Joaquim Jose Santos},
  editor = {Vinod, Hrishikesh D. and Rao, C. R.},
  date = {2019-01-01},
  series = {Conceptual {{Econometrics Using R}}},
  volume = {41},
  pages = {245--279},
  publisher = {Elsevier},
  doi = {10.1016/bs.host.2018.11.008},
  url = {https://www.sciencedirect.com/science/article/pii/S0169716118301019},
  urldate = {2021-04-07},
  abstract = {Often, the dependent variable in regression models has a fractional nature, being bounded in the unit interval. Several variants of cross-sectional and panel data fractional regression models have recently been proposed. This chapter shows how to estimate most of those models by using three R packages: frm, frmhet, and frmpd.},
  langid = {english},
  keywords = {Endogeneity,Exponential regression,Fractional responses,Heterogeneity,Panel data,Partial effects,Prediction,R,Smearing estimator,Specification tests,Two-part models},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\R\Ramalho_2019_Chapter 8 - Modeling fractional responses using R.pdf}
}

@article{douma2019AnalysingContinuousProportions,
  title = {Analysing Continuous Proportions in Ecology and Evolution: {{A}} Practical Introduction to Beta and {{Dirichlet}} Regression},
  shorttitle = {Analysing Continuous Proportions in Ecology and Evolution},
  author = {Douma, Jacob C. and Weedon, James T.},
  date = {2019},
  journaltitle = {Methods in Ecology and Evolution},
  volume = {10},
  number = {9},
  pages = {1412--1430},
  issn = {2041-210X},
  doi = {10.1111/2041-210X.13234},
  url = {https://besjournals.onlinelibrary.wiley.com/doi/abs/10.1111/2041-210X.13234},
  urldate = {2021-04-13},
  abstract = {Proportional data, in which response variables are expressed as percentages or fractions of a whole, are analysed in many subfields of ecology and evolution. The scale-independence of proportions makes them appropriate to analyse many biological phenomena, but statistical analyses are not straightforward, since proportions can only take values from zero to one and their variance is usually not constant across the range of the predictor. Transformations to overcome these problems are often applied, but can lead to biased estimates and difficulties in interpretation. In this paper, we provide an overview of the different types of proportional data and discuss the different analysis strategies available. In particular, we review and discuss the use of promising, but little used, techniques for analysing continuous (also called non-count-based or non-binomial) proportions (e.g. percent cover, fraction time spent on an activity): beta and Dirichlet regression, and some of their most important extensions. A major distinction can be made between proportions arising from counts and those arising from continuous measurements. For proportions consisting of two categories, count-based data are best analysed using well-developed techniques such as logistic regression, while continuous proportions can be analysed with beta regression models. In the case of {$>$}2 categories, multinomial logistic regression or Dirichlet regression can be applied. Both beta and Dirichlet regression techniques model proportions at their original scale, which makes statistical inference more straightforward and produce less biased estimates relative to transformation-based solutions. Extensions to beta regression, such as models for variable dispersion, zero-one augmented data and mixed effects designs have been developed and are reviewed and applied to case studies. Finally, we briefly discuss some issues regarding model fitting, inference, and reporting that are particularly relevant to beta and Dirichlet regression. Beta regression and Dirichlet regression overcome some problems inherent in applying classic statistical approaches to proportional data. To facilitate the adoption of these techniques by practitioners in ecology and evolution, we present detailed, annotated demonstration scripts covering all variations of beta and Dirichlet regression discussed in the article, implemented in the freely available language for statistical computing, r.},
  langid = {english},
  keywords = {beta regression,Dirichlet regression,fractions,non-count proportions,one augmented,proportions,transformations,zero augmented},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\D\Douma_Weedon_2019_Analysing continuous proportions in ecology and evolution.pdf}
}

@article{cebrian2015NHPoissonPackageFitting,
  title = {{{NHPoisson}}: {{An R Package}} for {{Fitting}} and {{Validating Nonhomogeneous Poisson Processes}}},
  shorttitle = {{{{\textbf{NHPoisson}}}}},
  author = {Cebrián, Ana C. and Abaurrea, Jesús and Asín, Jesús},
  date = {2015},
  journaltitle = {Journal of Statistical Software},
  shortjournal = {J. Stat. Soft.},
  volume = {64},
  number = {6},
  issn = {1548-7660},
  doi = {10.18637/jss.v064.i06},
  url = {http://www.jstatsoft.org/v64/i06/},
  urldate = {2021-04-14},
  abstract = {NHPoisson is an R package for the modeling of nonhomogeneous Poisson processes in one dimension. It includes functions for data preparation, maximum likelihood estimation, covariate selection and inference based on asymptotic distributions and simulation methods. It also provides specific methods for the estimation of Poisson processes resulting from a peak over threshold approach. In addition, the package supports a wide range of model validation tools and functions for generating nonhomogenous Poisson process trajectories. This paper is a description of the package and aims to help those interested in modeling data using nonhomogeneous Poisson processes.},
  langid = {english},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\C\Cebrián et al_2015_NHPoisson.pdf}
}

@article{lichstein2007MultipleRegressionDistance,
  title = {Multiple Regression on Distance Matrices: A Multivariate Spatial Analysis Tool},
  shorttitle = {Multiple Regression on Distance Matrices},
  author = {Lichstein, Jeremy W.},
  date = {2007-01-08},
  journaltitle = {Plant Ecology},
  shortjournal = {Plant Ecol},
  volume = {188},
  number = {2},
  pages = {117--131},
  issn = {1385-0237, 1573-5052},
  doi = {10.1007/s11258-006-9126-3},
  url = {http://link.springer.com/10.1007/s11258-006-9126-3},
  urldate = {2021-04-14},
  abstract = {I explore the use of multiple regression on distance matrices (MRM), an extension of partial Mantel analysis, in spatial analysis of ecological data. MRM involves a multiple regression of a response matrix on any number of explanatory matrices, where each matrix contains distances or similarities (in terms of ecological, spatial, or other attributes) between all pair-wise combinations of n objects (sample units); tests of statistical significance are performed by permutation. The method is flexible in terms of the types of data that may be analyzed (counts, presence –absence, continuous, categorical) and the shapes of response curves. MRM offers several advantages over traditional partial Mantel analysis: (1) separating environmental distances into distinct distance matrices allows inferences to be made at the level of individual variables; (2) nonparametric or nonlinear multiple regression methods may be employed; and (3) spatial autocorrelation may be quantified and tested at different spatial scales using a series of lag matrices, each representing a geographic distance class. The MRM lag matrices model may be parameterized to yield very similar inferences regarding spatial autocorrelation as the Mantel correlogram. Unlike the correlogram, however, the lag matrices model may also include environmental distance matrices, so that spatial patterns in species abundance distances (community similarity) may be quantified while controlling for the environmental similarity between sites. Examples of spatial analyses with MRM are presented.},
  langid = {english},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\L\Lichstein_2007_Multiple regression on distance matrices.pdf}
}

@article{alonso2015AnalyticalMethodsUntargeted,
  title = {Analytical {{Methods}} in {{Untargeted Metabolomics}}: {{State}} of the {{Art}} in 2015},
  shorttitle = {Analytical {{Methods}} in {{Untargeted Metabolomics}}},
  author = {Alonso, Arnald and Marsal, Sara and JuliÃ, Antonio},
  date = {2015-03-05},
  journaltitle = {Frontiers in Bioengineering and Biotechnology},
  shortjournal = {Front. Bioeng. Biotechnol.},
  volume = {3},
  issn = {2296-4185},
  doi = {10.3389/fbioe.2015.00023},
  url = {http://www.frontiersin.org/Bioinformatics_and_Computational_Biology/10.3389/fbioe.2015.00023/abstract},
  urldate = {2021-04-14},
  abstract = {Metabolomics comprises the methods and techniques that are used to measure the small molecule composition of biofluids and tissues, and is actually one of the most rapidly evolving research fields. The determination of the metabolomic profile – the metabolome –has multiple applications in many biological sciences, including the developing of new diagnostic tools in medicine. Recent technological advances in nuclear magnetic resonance and mass spectrometry are significantly improving our capacity to obtain more data from each biological sample. Consequently, there is a need for fast and accurate statistical and bioinformatic tools that can deal with the complexity and volume of the data generated in metabolomic studies. In this review, we provide an update of the most commonly used analytical methods in metabolomics, starting from raw data processing and ending with pathway analysis and biomarker identification. Finally, the integration of metabolomic profiles with molecular data from other high-throughput biotechnologies is also reviewed.},
  langid = {english},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\A\Alonso et al_2015_Analytical Methods in Untargeted Metabolomics.pdf}
}

@article{kuznetsova2017LmerTestPackageTests,
  title = {{{lmerTest Package}}: {{Tests}} in {{Linear Mixed Effects Models}}},
  shorttitle = {{{{\textbf{lmerTest}}}} {{Package}}},
  author = {Kuznetsova, Alexandra and Brockhoff, Per B. and Christensen, Rune H. B.},
  date = {2017},
  journaltitle = {Journal of Statistical Software},
  shortjournal = {J. Stat. Soft.},
  volume = {82},
  number = {13},
  issn = {1548-7660},
  doi = {10.18637/jss.v082.i13},
  url = {http://www.jstatsoft.org/v82/i13/},
  urldate = {2021-04-14},
  abstract = {One of the frequent questions by users of the mixed model function lmer of the lme4 package has been: How can I get p values for the F and t tests for objects returned by lmer? The lmerTest package extends the ‘lmerMod’ class of the lme4 package, by overloading the anova and summary functions by providing p values for tests for fixed effects. We have implemented the Satterthwaite’s method for approximating degrees of freedom for the t and F tests. We have also implemented the construction of Type I–III ANOVA tables. Furthermore, one may also obtain the summary as well as the anova table using the Kenward-Roger approximation for denominator degrees of freedom (based on the KRmodcomp function from the pbkrtest package). Some other convenient mixed model analysis tools such as a step method, that performs backward elimination of nonsignificant effects – both random and fixed, calculation of population means and multiple comparison tests together with plot facilities are provided by the package as well.},
  langid = {english},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\K\Kuznetsova et al_2017_lmerTest Package.pdf}
}

@article{cribari-neto2010BetaRegression,
  title = {Beta {{Regression}} in {{R}}},
  author = {Cribari-Neto, Francisco and Zeileis, Achim},
  date = {2010-04-05},
  journaltitle = {Journal of Statistical Software},
  volume = {34},
  number = {1},
  pages = {1--24},
  issn = {1548-7660},
  doi = {10.18637/jss.v034.i02},
  url = {https://www.jstatsoft.org/index.php/jss/article/view/v034i02},
  urldate = {2021-04-16},
  issue = {1},
  langid = {english},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\C\Cribari-Neto_Zeileis_2010_Beta Regression in R.pdf}
}

@article{warton2011ArcsineAsinineAnalysis,
  title = {The Arcsine Is Asinine: The Analysis of Proportions in Ecology},
  shorttitle = {The Arcsine Is Asinine},
  author = {Warton, David I. and Hui, Francis K. C.},
  date = {2011},
  journaltitle = {Ecology},
  volume = {92},
  number = {1},
  pages = {3--10},
  issn = {1939-9170},
  doi = {10.1890/10-0340.1},
  url = {https://esajournals.onlinelibrary.wiley.com/doi/abs/10.1890/10-0340.1},
  urldate = {2021-04-16},
  abstract = {The arcsine square root transformation has long been standard procedure when analyzing proportional data in ecology, with applications in data sets containing binomial and non-binomial response variables. Here, we argue that the arcsine transform should not be used in either circumstance. For binomial data, logistic regression has greater interpretability and higher power than analyses of transformed data. However, it is important to check the data for additional unexplained variation, i.e., overdispersion, and to account for it via the inclusion of random effects in the model if found. For non-binomial data, the arcsine transform is undesirable on the grounds of interpretability, and because it can produce nonsensical predictions. The logit transformation is proposed as an alternative approach to address these issues. Examples are presented in both cases to illustrate these advantages, comparing various methods of analyzing proportions including untransformed, arcsine- and logit-transformed linear models and logistic regression (with or without random effects). Simulations demonstrate that logistic regression usually provides a gain in power over other methods.},
  langid = {english},
  keywords = {arcsine transformation,binomial,generalized linear mixed models,logistic regression,logit transformation,overdispersion,power,Type I error},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\W\Warton_Hui_2011_The arcsine is asinine.pdf}
}

@unpublished{cevid2020DistributionalRandomForests,
  title = {Distributional {{Random Forests}}: {{Heterogeneity Adjustment}} and {{Multivariate Distributional Regression}}},
  shorttitle = {Distributional {{Random Forests}}},
  author = {Ćevid, Domagoj and Michel, Loris and Meinshausen, Nicolai and Bühlmann, Peter},
  date = {2020-05-29},
  eprint = {2005.14458},
  eprinttype = {arXiv},
  eprintclass = {cs, stat},
  url = {http://arxiv.org/abs/2005.14458},
  urldate = {2021-04-16},
  abstract = {We propose an adaptation of the Random Forest algorithm to estimate the conditional distribution of a possibly multivariate response. We suggest a new splitting criterion based on the MMD two-sample test, which is suitable for detecting heterogeneity in multivariate distributions. The weights provided by the forest can be conveniently used as an input to other methods in order to locally solve various learning problems. The code is available as \textbackslash texttt\{R\}-package \textbackslash texttt\{drf\}.},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning,Statistics - Methodology},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\E\Ćevid et al_2020_Distributional Random Forests.pdf}
}

@article{meinshausenQuantileRegressionForests,
  title = {Quantile {{Regression Forests}}},
  author = {Meinshausen, Nicolai},
  pages = {17},
  abstract = {Random forests were introduced as a machine learning tool in Breiman (2001) and have since proven to be very popular and powerful for high-dimensional regression and classification. For regression, random forests give an accurate approximation of the conditional mean of a response variable. It is shown here that random forests provide information about the full conditional distribution of the response variable, not only about the conditional mean. Conditional quantiles can be inferred with quantile regression forests, a generalisation of random forests. Quantile regression forests give a non-parametric and accurate way of estimating conditional quantiles for high-dimensional predictor variables. The algorithm is shown to be consistent. Numerical examples suggest that the algorithm is competitive in terms of predictive power.},
  langid = {english},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\M\Meinshausen_Quantile Regression Forests.pdf}
}

@article{marchant2011SpatialPredictionSoil,
  title = {Spatial Prediction of Soil Properties with Copulas},
  author = {Marchant, B. P. and Saby, N. P. A. and Jolivet, C. C. and Arrouays, D. and Lark, R. M.},
  date = {2011-05-15},
  journaltitle = {Geoderma},
  shortjournal = {Geoderma},
  volume = {162},
  number = {3},
  pages = {327--334},
  issn = {0016-7061},
  doi = {10.1016/j.geoderma.2011.03.005},
  url = {https://www.sciencedirect.com/science/article/pii/S0016706111000681},
  urldate = {2021-04-19},
  abstract = {The uncertainty of a prediction of a spatial property may only be fully described if the property is assumed to be a realization of a multivariate random variable. Model-based geostatistical methods are generally based on the assumption that the random variable is multivariate Gaussian. However this model is implausible for many soil properties. For example, observations of cadmium concentrations from the French National Soil Monitoring Network include outliers which arise because of isolated pollution and other local anomalies. We introduce a more general multivariate function for the spatial analysis of soil properties based on copulas. The dependence structure and marginal distributions of this function are specified separately. A copula-based model with a Gaussian dependence structure and generalized extreme value marginal distributions is fitted to the observations of cadmium across France. The expected concentration of cadmium is permitted to vary with parent material. This model is used to predict the distribution of cadmium concentrations at unsampled sites conditional on the observed data. Upon cross-validation the copula-based model performs better than existing model-based approaches. However further generalizations, such as the use of non-Gaussian copulas, are required to ensure a complete description of the complexity of the variation of cadmium in French soils.},
  langid = {english},
  keywords = {Cadmium,Geostatistics,Multivariate distribution,Uncertainty},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\M\Marchant et al_2011_Spatial prediction of soil properties with copulas.pdf}
}

@book{rice2007MathematicalStatisticsData,
  title = {Mathematical Statistics and Data Analysis},
  author = {Rice, John A.},
  date = {2007},
  series = {Duxbury Advanced Series},
  edition = {3rd ed},
  publisher = {Thomson/Brooks/Cole},
  location = {Belmont, CA},
  isbn = {978-0-534-39942-9},
  langid = {english},
  pagetotal = {1},
  keywords = {Book,Stat},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\R\Rice_2007_Mathematical statistics and data analysis.pdf}
}

@book{held2014AppliedStatisticalInference,
  title = {Applied {{Statistical Inference}}},
  author = {Held, Leonhard and Sabanés Bové, Daniel},
  date = {2014},
  publisher = {Springer Berlin Heidelberg},
  location = {Berlin, Heidelberg},
  doi = {10.1007/978-3-642-37887-4},
  url = {http://link.springer.com/10.1007/978-3-642-37887-4},
  urldate = {2021-04-24},
  isbn = {978-3-642-37886-7 978-3-642-37887-4},
  langid = {english},
  keywords = {Book,Stat},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\H\Held_Sabanés Bové_2014_Applied Statistical Inference.pdf}
}

@article{green2016SIMRPackagePower,
  title = {{{SIMR}}: An {{R}} Package for Power Analysis of Generalized Linear Mixed Models by Simulation},
  shorttitle = {{{SIMR}}},
  author = {Green, Peter and MacLeod, Catriona J.},
  date = {2016},
  journaltitle = {Methods in Ecology and Evolution},
  volume = {7},
  number = {4},
  pages = {493--498},
  issn = {2041-210X},
  doi = {10.1111/2041-210X.12504},
  url = {https://besjournals.onlinelibrary.wiley.com/doi/abs/10.1111/2041-210X.12504},
  urldate = {2021-04-26},
  abstract = {The r package simr allows users to calculate power for generalized linear mixed models from the lme4 package. The power calculations are based on Monte Carlo simulations. It includes tools for (i) running a power analysis for a given model and design; and (ii) calculating power curves to assess trade-offs between power and sample size. This paper presents a tutorial using a simple example of count data with mixed effects (with structure representative of environmental monitoring data) to guide the user along a gentle learning curve, adding only a few commands or options at a time.},
  langid = {english},
  keywords = {experimental design,glmm,Monte Carlo,random effects,sample size,type II error},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\G\Green_MacLeod_2016_SIMR.pdf}
}

@book{dmkdeutschschweizerischemathematikkommissionherrrenekaeslin2019FormelnTabellenBegriffe,
  title = {Formeln, Tabellen, Begriffe Mathematik - Physik - Chemie},
  editor = {DMK Deutschschweizerische Mathematikkommission Herr René Kaeslin and DPK Deutschschweizerische Physikkommission Herr Remo Jakob and DCK Deutschschweizer Chemiekommission},
  date = {2019},
  edition = {7. durchgesehene Auflage},
  publisher = {Orell Füssli Verlag},
  location = {Zürich},
  isbn = {978-3-280-04193-2},
  langid = {german},
  pagetotal = {263},
  keywords = {(BISAC Subject Heading)EDU029010: EDUCATION / Teaching Methods & Materials / Mathematics,(Produktform)Paperback / softback,(VLB-WN)1844: Hardcover Softcover / Schule Lernen/Lernhilfen Abiturwissen/Sekundarstufe II,Book,Formelsammlung}
}

@unpublished{rasmussen2018LectureNotesTemporal,
  title = {Lecture {{Notes}}: {{Temporal Point Processes}} and the {{Conditional Intensity Function}}},
  shorttitle = {Lecture {{Notes}}},
  author = {Rasmussen, Jakob Gulddahl},
  date = {2018-06-01},
  eprint = {1806.00221},
  eprinttype = {arXiv},
  eprintclass = {stat},
  url = {http://arxiv.org/abs/1806.00221},
  urldate = {2021-05-07},
  abstract = {These short lecture notes contain a not too technical introduction to point processes on the time line. The focus lies on defining these processes using the conditional intensity function. Furthermore, likelihood inference, methods of simulation and residual analysis for temporal point processes specified by a conditional intensity function are considered.},
  langid = {english},
  keywords = {Statistics - Methodology},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\R\Rasmussen_2018_Lecture Notes.pdf}
}

@article{cressie2006BlockKrigingLognormal,
  title = {Block {{Kriging}} for {{Lognormal Spatial Processes}}},
  author = {Cressie, Noel},
  date = {2006-12-13},
  journaltitle = {Mathematical Geology},
  shortjournal = {Math Geol},
  volume = {38},
  number = {4},
  pages = {413--443},
  issn = {0882-8121, 1573-8868},
  doi = {10.1007/s11004-005-9022-8},
  url = {http://link.springer.com/10.1007/s11004-005-9022-8},
  urldate = {2021-05-20},
  abstract = {Lognormal spatial data are common in mining and soil-science applications. Modeling the underlying spatial process as normal on the log scale is sensible; point kriging allows the whole region of interest to be mapped. However, mining and precision agriculture is carried out selectively and is based on block averages of the process on the original scale. Finding spatial predictions of the blocks assuming a lognormal spatial process has a long history in geostatistics. In this article, we make the case that a particular method for block prediction, overlooked in past times of low computing power, deserves to be reconsidered. In fact, for known mean, it is optimal. We also consider the predictor based on the “law” of permanence of lognormality. Mean squared prediction errors of both are derived and compared both theoretically and via simulation; the predictor based on the permanence-of-lognormality assumption is seen to be less efficient. Our methodology is applied to block kriging of phosphorus to guide precision-agriculture treatment of soil on Broom’s Barn Farm, UK.},
  langid = {english},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\C\Cressie_2006_Block Kriging for Lognormal Spatial Processes.pdf}
}

@article{nussbaum2014EstimatingSoilOrganic,
  title = {Estimating Soil Organic Carbon Stocks of {{Swiss}} Forest Soils by Robust External-Drift Kriging},
  author = {Nussbaum, M. and Papritz, A. and Baltensweiler, A. and Walthert, L.},
  date = {2014-06-25},
  journaltitle = {Geoscientific Model Development},
  shortjournal = {Geosci. Model Dev.},
  volume = {7},
  number = {3},
  pages = {1197--1210},
  issn = {1991-9603},
  doi = {10.5194/gmd-7-1197-2014},
  url = {https://gmd.copernicus.org/articles/7/1197/2014/},
  urldate = {2021-05-20},
  abstract = {Accurate estimates of soil organic carbon (SOC) stocks are required to quantify carbon sources and sinks caused by land use change at national scale. This study presents a novel robust kriging method to precisely estimate regional and national mean SOC stocks, along with truthful standard errors. We used this new approach to estimate mean forest SOC stock for Switzerland and for its five main ecoregions.},
  langid = {english},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\N\Nussbaum et al_2014_Estimating soil organic carbon stocks of Swiss forest soils by robust.pdf}
}

@article{harte2010PtProcessPackageModelling,
  title = {{{PtProcess}}: {{An R Package}} for {{Modelling Marked Point Processes Indexed}} by {{Time}}},
  shorttitle = {{{PtProcess}}},
  author = {Harte, David},
  date = {2010-07-26},
  journaltitle = {Journal of Statistical Software},
  volume = {35},
  number = {1},
  pages = {1--32},
  issn = {1548-7660},
  doi = {10.18637/jss.v035.i08},
  url = {https://www.jstatsoft.org/index.php/jss/article/view/v035i08},
  urldate = {2021-05-21},
  issue = {1},
  langid = {english},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\H\Harte_2010_PtProcess.pdf}
}

@article{cowling1996BootstrapConfidenceRegions,
  title = {Bootstrap {{Confidence Regions}} for the {{Intensity}} of a {{Poisson Point Process}}},
  author = {Cowling, Ann and Hall, Peter and Phillips, Michael J},
  date = {1996},
  pages = {10},
  langid = {english},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\C\Cowling et al_1996_Bootstrap Confidence Regions for the Intensity of a Poisson Point Process.pdf}
}

@article{senn2006ChangeBaselineAnalysis,
  title = {Change from Baseline and Analysis of Covariance Revisited},
  author = {Senn, Stephen},
  date = {2006},
  journaltitle = {Statistics in Medicine},
  volume = {25},
  number = {24},
  pages = {4334--4344},
  issn = {1097-0258},
  doi = {10.1002/sim.2682},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.2682},
  urldate = {2021-06-04},
  abstract = {The case for preferring analysis of covariance (ANCOVA) to the simple analysis of change scores (SACS) has often been made. Nevertheless, claims continue to be made that analysis of covariance is biased if the groups are not equal at baseline. If the required equality were in expectation only, this would permit the use of ANCOVA in randomized clinical trials but not in observational studies. The discussion is related to Lord's paradox. In this note, it is shown, however that it is not a necessary condition for groups to be equal at baseline, not even in expectation, for ANCOVA to provide unbiased estimates of treatment effects. It is also shown that although many situations can be envisaged where ANCOVA is biased it is very difficult to imagine circumstances under which SACS would then be unbiased and a causal interpretation could be made. Copyright © 2006 John Wiley \& Sons, Ltd.},
  langid = {english},
  keywords = {analysis of covariance,baselines,change score,Lord's paradox,repeated measures},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\S\Senn_2006_Change from baseline and analysis of covariance revisited.pdf}
}

@article{matloffArtProgramming,
  title = {The {{Art}} of {{R Programming}}},
  author = {Matloff, Norman},
  pages = {404},
  langid = {english},
  keywords = {Book,R},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\M\Matloff_The Art of R Programming.pdf}
}

@book{grolemund2014HandsonProgramming,
  title = {Hands-on Programming with {{R}}},
  author = {Grolemund, Garrett},
  date = {2014},
  edition = {First edition},
  publisher = {O'Reilly},
  location = {Sebastopol, CA},
  isbn = {978-1-4493-5901-0},
  langid = {english},
  pagetotal = {230},
  keywords = {Data processing,Handbooks manuals etc,Mathematical statistics,Programmeertalen,R (Computer program language),Statistiek},
  annotation = {OCLC: ocn887746093},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\G\Grolemund_2014_Hands-on programming with R.pdf}
}

@misc{rcoreteam2021Introduction,
  title = {An {{Introduction}} to {{R}}},
  author = {R Core Team},
  date = {2021},
  url = {https://cran.r-project.org/doc/manuals/r-release/R-intro.pdf},
  urldate = {2021-06-17},
  keywords = {Book,R},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\R\R Core Team_2021_An Introduction to R.pdf}
}

@book{adler2012Nutshell,
  title = {R in a Nutshell},
  author = {Adler, Joseph},
  date = {2012},
  edition = {Second edition},
  publisher = {O'Reilly},
  location = {Beijing},
  isbn = {978-1-4493-1208-4},
  pagetotal = {699},
  keywords = {Book,Data processing,Mathematical statistics,R,R (Computer program language)},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\A\Adler_2012_R in a nutshell.pdf}
}

@misc{grossReader,
  title = {R {{Reader}}},
  author = {Groß, Jörg and Peters, Benjamin},
  keywords = {Book,R},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\G\Groß_Peters_R Reader.pdf}
}

@book{davies2016BookFirstCourse,
  title = {The Book of {{R}}: A First Course in Programming and Statistics},
  shorttitle = {The Book of {{R}}},
  author = {Davies, Tilman M.},
  date = {2016},
  publisher = {No Starch Press},
  location = {San Francisco},
  abstract = {"A beginner's guide to programming with R, the statistical programming language. Covers key programming techniques like manipulating data structures, reading data from a file, and writing functions. Introduces statistics topics like probability distributions, hypothesis testing, regression analysis, and statistical plots. Includes exercises throughout each chapter"--},
  isbn = {978-1-59327-651-5},
  pagetotal = {792},
  keywords = {Book,Computer programming,Data processing,R,R (Computer program language),Statistics},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\D\Davies_2016_The book of R.pdf}
}

@book{kabacoff2015ActionDataAnalysis,
  title = {R in Action: Data Analysis and Graphics with {{R}}},
  shorttitle = {R in Action},
  author = {Kabacoff, Robert},
  date = {2015},
  edition = {Second edition},
  publisher = {Manning},
  location = {Shelter Island},
  isbn = {978-1-61729-138-8},
  langid = {english},
  pagetotal = {579},
  keywords = {Book,Data processing,R,R (Computer program language),Statistics},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\K\Kabacoff_2015_R in action.pdf}
}

@book{baddeley2016SpatialPointPatterns,
  title = {Spatial Point Patterns: Methodology and Applications with {{R}}},
  shorttitle = {Spatial Point Patterns},
  author = {Baddeley, Adrian and Rubak, Ege and Turner, Rolf},
  date = {2016},
  series = {Chapman \& {{Hall}}/{{CRC}} Interdisciplinary Statistics Series},
  publisher = {CRC Press},
  location = {Boca Raton London New York},
  isbn = {978-1-4822-1021-7 978-1-4822-1020-0},
  langid = {english},
  pagetotal = {810},
  keywords = {Book,Stat},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\B\Baddeley et al_2016_Spatial point patterns.pdf}
}

@book{davison1997BootstrapMethodsTheir,
  title = {Bootstrap {{Methods}} and Their {{Application}}},
  author = {Davison, A. C. and Hinkley, D. V.},
  date = {1997},
  series = {Cambridge {{Series}} in {{Statistical}} and {{Probabilistic Mathematics}}},
  publisher = {Cambridge University Press},
  location = {Cambridge},
  doi = {10.1017/CBO9780511802843},
  url = {https://www.cambridge.org/core/books/bootstrap-methods-and-their-application/ED2FD043579F27952363566DC09CBD6A},
  urldate = {2021-08-13},
  abstract = {Bootstrap methods are computer-intensive methods of statistical analysis, which use simulation to calculate standard errors, confidence intervals, and significance tests. The methods apply for any level of modelling, and so can be used for fully parametric, semiparametric, and completely nonparametric analysis. This 1997 book gives a broad and up-to-date coverage of bootstrap methods, with numerous applied examples, developed in a coherent way with the necessary theoretical basis. Applications include stratified data; finite populations; censored and missing data; linear, nonlinear, and smooth regression models; classification; time series and spatial problems. Special features of the book include: extensive discussion of significance tests and confidence intervals; material on various diagnostic methods; and methods for efficient computation, including improved Monte Carlo simulation. Each chapter includes both practical and theoretical exercises. S-Plus programs for implementing the methods described in the text are available from the supporting website.},
  isbn = {978-0-521-57471-6},
  keywords = {Book,Stat},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\D\Davison_Hinkley_1997_Bootstrap Methods and their Application.pdf}
}

@article{vickers2001AnalysingControlledTrials,
  title = {Analysing Controlled Trials with Baseline and Follow up Measurements},
  author = {Vickers, Andrew J. and Altman, Douglas G.},
  date = {2001-11-10},
  journaltitle = {BMJ},
  shortjournal = {BMJ},
  volume = {323},
  number = {7321},
  eprint = {11701584},
  eprinttype = {pmid},
  pages = {1123--1124},
  publisher = {British Medical Journal Publishing Group},
  issn = {0959-8138, 1468-5833},
  doi = {10.1136/bmj.323.7321.1123},
  url = {https://www.bmj.com/content/323/7321/1123},
  urldate = {2021-09-06},
  abstract = {In many randomised trials researchers measure a continuous variable at baseline and again as an outcome assessed at follow up. Baseline measurements are common in trials of chronic conditions where researchers want to see whether a treatment can reduce pre-existing levels of pain, anxiety, hypertension, and the like. Statistical comparisons in such trials can be made in several ways. Comparison of follow up (post-treatment) scores will give a result such as “at the end of the trial, mean pain scores were 15 mm (95\% confidence interval 10 to 20 mm) lower in the treatment group.” Alternatively a change score can be calculated by subtracting the follow up score from the baseline score, leading to a statement such as “pain reductions were 20 mm (16 to 24 mm) greater on treatment than control.” If the average baseline scores are the same in each group the estimated treatment effect will be the same using these two simple approaches. If the treatment is effective the statistical significance of the treatment effect by the two methods will depend on the correlation between baseline and follow up scores. If the correlation is low using the change score will …},
  langid = {english},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\V\Vickers_Altman_2001_Analysing controlled trials with baseline and follow up measurements.pdf}
}

@book{lohr2019SamplingDesignAnalysis,
  title = {Sampling: {{Design}} and {{Analysis}}},
  shorttitle = {Sampling},
  author = {Lohr, Sharon L.},
  date = {2019-04-09},
  edition = {2nd edition},
  publisher = {{Chapman and Hall/CRC}},
  location = {Boca Raton, FL London New York},
  abstract = {This edition is a reprint of the second edition published by Cengage Learning, Inc. Reprinted with permission. What is the unemployment rate? How many adults have high blood pressure? What is the total area of land planted with soybeans? Sampling: Design and Analysis tells you how to design and analyze surveys to answer these and other questions. This authoritative text, used as a standard reference by numerous survey organizations, teaches sampling using real data sets from social sciences, public opinion research, medicine, public health, economics, agriculture, ecology, and other fields. The book is accessible to students from a wide range of statistical backgrounds. By appropriate choice of sections, it can be used for a graduate class for statistics students or for a class with students from business, sociology, psychology, or biology. Readers should be familiar with concepts from an introductory statistics class including linear regression; optional sections contain the statistical theory, for readers who have studied mathematical statistics. Distinctive features include:   More than 450 exercises. In each chapter, Introductory Exercises develop skills, Working with Data Exercises give practice with data from surveys, Working with Theory Exercises allow students to investigate statistical properties of estimators, and Projects and Activities Exercises integrate concepts. A solutions manual is available.   An emphasis on survey design.   Coverage of simple random, stratified, and cluster sampling; ratio estimation; constructing survey weights; jackknife and bootstrap; nonresponse; chi-squared tests and regression analysis.   Graphing data from surveys.   Computer code using SAS® software.   Online supplements containing data sets, computer programs, and additional material.  Sharon Lohr, the author of Measuring Crime: Behind the Statistics, has published widely about survey sampling and statistical methods for education, public policy, law, and crime. She has been recognized as Fellow of the American Statistical Association, elected member of the International Statistical Institute, and recipient of the Gertrude M. Cox Statistics Award and the Deming Lecturer Award. Formerly Dean’s Distinguished Professor of Statistics at Arizona State University and a Vice President at Westat, she is now a freelance statistical consultant and writer. Visit her website at www.sharonlohr.com.},
  isbn = {978-0-367-27341-5},
  langid = {english},
  pagetotal = {610},
  keywords = {Book,Stat},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\L\Lohr_2019_Sampling.pdf}
}

@book{cochran1977SamplingTechniques,
  title = {Sampling Techniques},
  author = {Cochran, William Gemmell},
  date = {1977},
  series = {Wiley Series in Probability and Mathematical Statistics},
  edition = {3d ed},
  publisher = {Wiley},
  location = {New York},
  isbn = {978-0-471-16240-7},
  langid = {english},
  pagetotal = {428},
  keywords = {Book,Sampling (Statistics),Stat},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\C\Cochran_1977_Sampling techniques.pdf}
}

@article{groemping2007RelativeImportanceLinear,
  title = {Relative {{Importance}} for {{Linear Regression}} in {{R}}: {{The Package}} Relaimpo},
  shorttitle = {Relative {{Importance}} for {{Linear Regression}} in {{R}}},
  author = {Groemping, Ulrike},
  date = {2007},
  journaltitle = {Journal of Statistical Software},
  volume = {17},
  pages = {1--27},
  issn = {1548-7660},
  doi = {10.18637/jss.v017.i01},
  url = {https://doi.org/10.18637/jss.v017.i01},
  urldate = {2022-05-12},
  abstract = {Relative importance is a topic that has seen a lot of interest in recent years, particularly in applied work. The R package relaimpo implements six different metrics for assessing relative importance of regressors in the linear model, two of which are recommended - averaging over orderings of regressors and a newly proposed metric (Feldman 2005) called pmvd. Apart from delivering the metrics themselves, relaimpo also provides (exploratory) bootstrap confidence intervals. This paper offers a brief tutorial introduction to the package.  The methods and relaimpo's functionality are illustrated using the data set swiss that is generally available in R. The paper targets readers who have a basic understanding of multiple linear regression. For the background of more advanced aspects, references are provided.},
  langid = {english},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\G\Groemping_2007_Relative Importance for Linear Regression in R.pdf}
}

@book{zhang2005AnalysisSurvivalData,
  title = {Analysis of {{Survival Data}}},
  author = {Zhang, Daowen},
  date = {2005},
  langid = {english},
  keywords = {Book,Stat},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\Z\Zhang_2005_Analysis of Survival Data.pdf}
}

@misc{weissteinerMasterThesisVariableImportance,
  title = {{{MasterThesis}}: {{Variable Importance}}},
  author = {Weissteiner},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\W\Weissteiner_MasterThesis.pdf}
}

@book{efron2016ComputerAgeStatistical,
  title = {Computer {{Age Statistical Inference}}},
  author = {Efron, Bradley and Hastie, Trevor},
  date = {2016},
  langid = {english},
  keywords = {Book,Stat},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\E\Efron_Hastie_2016_Computer Age Statistical Inference.pdf}
}

@incollection{bansak2021ConjointSurveyExperiments,
  title = {Conjoint {{Survey Experiments}}},
  booktitle = {Advances in {{Experimental Political Science}}},
  author = {Bansak, Kirk and Hainmueller, Jens and Hopkins, Daniel J. and Yamamoto, Teppei},
  editor = {Druckman, James and Green, Donald P.},
  date = {2021-04-01},
  edition = {1},
  pages = {19--41},
  publisher = {Cambridge University Press},
  doi = {10.1017/9781108777919.004},
  url = {https://www.cambridge.org/core/product/identifier/9781108777919%23c2/type/book_part},
  urldate = {2022-11-01},
  abstract = {Conjoint survey experiments have become a popular method for analyzing multidimensional preferences in political science. If properly implemented, conjoint experiments can obtain reliable measures of multidimensional preferences and estimate causal effects of multiple attributes on hypothetical choices or evaluations. This chapter provides an accessible overview of the methodology for designing, implementing, and analyzing conjoint survey experiments. Specifically, we begin by detailing a substantive example: How do candidate attributes affect the support of American respondents for candidates running against President Trump in 2020? We then discuss the theoretical underpinnings and advantages of conjoint designs. We next provide guidelines for practitioners in designing and analyzing conjoint survey experiments. We conclude by discussing further design considerations, common conjoint applications, common criticisms, and possible future directions.},
  isbn = {978-1-108-77791-9 978-1-108-47850-2 978-1-108-74588-8},
  langid = {english},
  keywords = {reading_list},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\B\Bansak et al_2021_Conjoint Survey Experiments.pdf}
}

@article{mckinnon2008IntroductionStatisticalMediation,
  title = {Introduction to {{Statistical Mediation Analysis}}},
  author = {McKinnon, David},
  date = {2008},
  pages = {490},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\M\McKinnon_2008_Introduction to Statistical Mediation Analysis.pdf}
}

@article{raftery1995BayesianModelSelection,
  title = {Bayesian {{Model Selection}} in {{Social Research}}},
  author = {Raftery, Adrian E.},
  date = {1995},
  journaltitle = {Sociological Methodology},
  shortjournal = {Sociological Methodology},
  volume = {25},
  eprint = {271063},
  eprinttype = {jstor},
  pages = {111},
  issn = {00811750},
  doi = {10.2307/271063},
  url = {https://www.jstor.org/stable/271063?origin=crossref},
  urldate = {2022-11-01},
  langid = {english},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\R\Raftery_1995_Bayesian Model Selection in Social Research.pdf}
}

@article{dekkers2012GaussianQuadratureEfficient,
  title = {Gaussian {{Quadrature}} Is an Efficient Method for the Back-Transformation in Estimating the Usual Intake Distribution When Assessing Dietary Exposure},
  author = {Dekkers, A.L.M. and Slob, W.},
  date = {2012-10},
  journaltitle = {Food and Chemical Toxicology},
  shortjournal = {Food and Chemical Toxicology},
  volume = {50},
  number = {10},
  pages = {3853--3861},
  issn = {02786915},
  doi = {10.1016/j.fct.2012.06.044},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0278691512004589},
  urldate = {2022-11-01},
  abstract = {In dietary exposure assessment, statistical methods exist for estimating the usual intake distribution from daily intake data. These methods transform the dietary intake data to normal observations, eliminate the within-person variance, and then back-transform the data to the original scale. We propose Gaussian Quadrature (GQ), a numerical integration method, as an efficient way of back-transformation. We compare GQ with six published methods. One method uses a log-transformation, while the other methods, including GQ, use a Box-Cox transformation. This study shows that, for various parameter choices, the methods with a Box-Cox transformation estimate the theoretical usual intake distributions quite well, although one method, a Taylor approximation, is less accurate. Two applications – on folate intake and fruit consumption – confirmed these results. In one extreme case, some methods, including GQ, could not be applied for low percentiles. We solved this problem by modifying GQ. One method is based on the assumption that the daily intakes are log-normally distributed. Even if this condition is not fulfilled, the log-transformation performs well as long as the within-individual variance is small compared to the mean. We conclude that the modified GQ is an efficient, fast and accurate method for estimating the usual intake distribution.},
  langid = {english},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\D\Dekkers_Slob_2012_Gaussian Quadrature is an efficient method for the back-transformation in.pdf}
}

@article{royston1994RegressionUsingFractional,
  title = {Regression {{Using Fractional Polynomials}} of {{Continuous Covariates}}: {{Parsimonious Parametric Modelling}}},
  shorttitle = {Regression {{Using Fractional Polynomials}} of {{Continuous Covariates}}},
  author = {Royston, Patrick and Altman, Douglas G.},
  date = {1994},
  journaltitle = {Applied Statistics},
  shortjournal = {Applied Statistics},
  volume = {43},
  number = {3},
  eprint = {2986270},
  eprinttype = {jstor},
  pages = {429},
  issn = {00359254},
  doi = {10.2307/2986270},
  url = {https://www.jstor.org/stable/2986270?origin=crossref},
  urldate = {2022-11-01},
  abstract = {The relationship between a response variable and one or more continuous covariates is often curved. Attempts to represent curvature in single- or multiple-regression models are usually made by means of polynomials of the covariates, typically quadratics. However, low order polynomials offer a limited family of shapes, and high order polynomials may fit poorly at the extreme values of the covariates. We propose an extended family of curves, which we call fractional polynomials, whose power terms are restricted to a small predefined set of integer and non-integer values. The powers are selected so that conventional polynomials are a subset of the family. Regression models using fractional polynomials of the covariates have appeared in the literature in an ad hoc fashion over a long period; we provide a unified description and a degree of formalization for them. They are shown to have considerable flexibility and are straightforward to fit using standard methods. We suggest an iterative algorithm for covariate selection and model fitting when several covariates are available. We give six examples of the use of fractional polynomial models in three types of regression analysis: normal errors, logistic and Cox regression. The examples all relate to medical data: fetal measurements, immunoglobulin concentrations in children, diabetes in children, infertility in women, myelomatosis (a type of leukaemia) and leg ulcers.},
  langid = {english},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\R\Royston_Altman_1994_Regression Using Fractional Polynomials of Continuous Covariates.pdf}
}

@article{sauerbrei1999BuildingMultivariablePrognostic,
  title = {Building Multivariable Prognostic and Diagnostic Models: Transformation of the Predictors by Using Fractional Polynomials},
  shorttitle = {Building Multivariable Prognostic and Diagnostic Models},
  author = {Sauerbrei, W. and Royston, P.},
  date = {1999-01},
  journaltitle = {Journal of the Royal Statistical Society: Series A (Statistics in Society)},
  shortjournal = {Journal of the Royal Statistical Society: Series A (Statistics in Society)},
  volume = {162},
  number = {1},
  pages = {71--94},
  issn = {0964-1998, 1467-985X},
  doi = {10.1111/1467-985X.00122},
  url = {https://onlinelibrary.wiley.com/doi/10.1111/1467-985X.00122},
  urldate = {2022-11-01},
  abstract = {To be useful to clinicians, prognostic and diagnostic indices must be derived from accurate models developed by using appropriate data sets. We show that fractional polynomials, which extend ordinary polynomials by including non-positive and fractional powers, may be used as the basis of such models. We describe how to fit fractional polynomials in several continuous covariates simultaneously, and we propose ways of ensuring that the resulting models are parsimonious and consistent with basic medical knowledge. The methods are applied to two breast cancer data sets, one from a prognostic factors study in patients with positive lymph nodes and the other from a study to diagnose malignant or benign tumours by using colour Doppler blood flow mapping. We investigate the problems of biased parameter estimates in the final model and overfitting using cross-validation calibration to estimate shrinkage factors. We adopt bootstrap resampling to assess model stability. We compare our new approach with conventional modelling methods which apply stepwise variables selection to categorized covariates. We conclude that fractional polynomial methodology can be very successful in generating simple and appropriate models.},
  langid = {english},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\S\Sauerbrei_Royston_1999_Building multivariable prognostic and diagnostic models.pdf}
}

@book{shalizi2021AdvancedDataAnalysis,
  title = {Advanced {{Data Analysis}} from an {{Elementary Point}} of {{View}}},
  author = {Shalizi, Cosma Rohilla},
  date = {2021},
  langid = {english},
  pagetotal = {861},
  keywords = {Book,reading_list,Stat},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\S\Shalizi_2021_Advanced Data Analysis from an Elementary Point of View.pdf}
}

@book{wickens1989MultiwayContingencyTables,
  title = {Multiway Contingency Tables Analysis for the Social Sciences},
  author = {Wickens, Thomas D.},
  date = {1989},
  publisher = {Lawrence Erlbaum Associates},
  location = {Hillsdale, N.J},
  isbn = {978-0-8058-0377-8 978-0-8058-0378-5},
  langid = {english},
  pagetotal = {426},
  keywords = {Book,Contingency tables,Mathematical statistics,reading_list,Social sciences,Stat,Statistical methods},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\W\Wickens_1989_Multiway contingency tables analysis for the social sciences.pdf}
}

@online{talts2020ValidatingBayesianInference,
  title = {Validating {{Bayesian Inference Algorithms}} with {{Simulation-Based Calibration}}},
  author = {Talts, Sean and Betancourt, Michael and Simpson, Daniel and Vehtari, Aki and Gelman, Andrew},
  date = {2020-10-21},
  eprint = {1804.06788},
  eprinttype = {arXiv},
  eprintclass = {stat},
  url = {http://arxiv.org/abs/1804.06788},
  urldate = {2022-11-01},
  abstract = {Verifying the correctness of Bayesian computation is challenging. This is especially true for complex models that are common in practice, as these require sophisticated model implementations and algorithms. In this paper we introduce simulation-based calibration (SBC), a general procedure for validating inferences from Bayesian algorithms capable of generating posterior samples. This procedure not only identifies inaccurate computation and inconsistencies in model implementations but also provides graphical summaries that can indicate the nature of the problems that arise. We argue that SBC is a critical part of a robust Bayesian workflow, as well as being a useful tool for those developing computational algorithms and statistical software.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {reading_list,Statistics - Methodology},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\T\Talts et al_2020_Validating Bayesian Inference Algorithms with Simulation-Based Calibration.pdf}
}

@article{hothorn2020MostLikelyTransformations,
  title = {Most {{Likely Transformations}}: {{The}} {\textbf{Mlt}} {{Package}}},
  shorttitle = {Most {{Likely Transformations}}},
  author = {Hothorn, Torsten},
  date = {2020},
  journaltitle = {Journal of Statistical Software},
  shortjournal = {J. Stat. Soft.},
  volume = {92},
  number = {1},
  issn = {1548-7660},
  doi = {10.18637/jss.v092.i01},
  url = {http://www.jstatsoft.org/v92/i01/},
  urldate = {2022-11-01},
  abstract = {The mlt package implements maximum likelihood estimation in the class of conditional transformation models. Based on a suitable explicit parameterization of the unconditional or conditional transformation function using infrastructure from package basefun, we show how one can define, estimate, and compare a cascade of increasingly complex transformation models in the maximum likelihood framework. Models for the unconditional or conditional distribution function of any univariate response variable are set-up and estimated in the same computational framework simply by choosing an appropriate transformation function and parameterization thereof. As it is computationally cheap to evaluate the distribution function, models can be estimated by maximization of the exact likelihood, especially in the presence of random censoring or truncation. The relatively dense high-level implementation in the R system for statistical computing allows generalization of many established implementations of linear transformation models, such as the Cox model or other parametric models for the analysis of survival or ordered categorical data, to the more complex situations illustrated in this paper.},
  langid = {english},
  keywords = {reading_list},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\H\Hothorn_2020_Most Likely Transformations.pdf}
}

@online{benhamou2018SevenProofsPearson,
  title = {Seven Proofs of the {{Pearson Chi-squared}} Independence Test and Its Graphical Interpretation},
  author = {Benhamou, Eric and Melot, Valentin},
  date = {2018-09-03},
  eprint = {1808.09171},
  eprinttype = {arXiv},
  eprintclass = {math, stat},
  url = {http://arxiv.org/abs/1808.09171},
  urldate = {2022-11-01},
  abstract = {This paper revisits the Pearson Chi-squared independence test. After presenting the underlying theory with modern notations and showing new way of deriving the proof, we describe an innovative and intuitive graphical presentation of this test. This enables not only interpreting visually the test but also measuring how close or far we are from accepting or rejecting the null hypothesis of non independence.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Mathematics - Statistics Theory,reading_list},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\B\Benhamou_Melot_2018_Seven proofs of the Pearson Chi-squared independence test and its graphical.pdf}
}

@article{choi2015ElucidatingFoundationsStatistical,
  title = {Elucidating the {{Foundations}} of {{Statistical Inference}} with 2 x 2 {{Tables}}},
  author = {Choi, Leena and Blume, Jeffrey D. and Dupont, William D.},
  editor = {Olivier, Jake},
  date = {2015-04-07},
  journaltitle = {PLOS ONE},
  shortjournal = {PLoS ONE},
  volume = {10},
  number = {4},
  pages = {e0121263},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0121263},
  url = {https://dx.plos.org/10.1371/journal.pone.0121263},
  urldate = {2022-11-01},
  langid = {english},
  keywords = {reading_list},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\C\Choi et al_2015_Elucidating the Foundations of Statistical Inference with 2 x 2 Tables.pdf}
}

@article{fifeEightStepsData,
  title = {The {{Eight Steps}} of {{Data Analysis}}: {{A Graphical Framework}} to {{Promote Sound Statistical Analysis}}},
  author = {Fife, Dustin},
  pages = {35},
  abstract = {Data analysis is a risky endeavor, particularly among those unaware of its dangers. In the words of Cook and Campbell (1976; see also Shadish, Cook, \& Campbell, 2002), “Statistical Conclusions Validity” threatens all research subjected to the dark arts of statistical magic. Although traditional statistics classes may advise against certain practices (e.g., multiple comparisons, small sample sizes, violating normality), they may fail to cover others (e.g., outlier detection and violating linearity). More common, perhaps, is that researchers may fail to remember them. In this paper, rather than rehashing old warnings and diatribes against this practice or that, I instead advocate a general statistical analysis strategy. This graphically-based eight step strategy promises to resolve the majority of statistical traps researchers may fall in without having to remember large lists of problematic statistical practices. These steps will assist in preventing both false positives and negatives and yield critical insights about the data that would have otherwise been missed. I conclude with an applied example that shows how the eight steps reveal interesting insights that would not be detected with standard statistical practices.},
  langid = {english},
  keywords = {reading_list},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\F\Fife_The Eight Steps of Data Analysis.pdf}
}

@article{franke2012ChiSquareTestOften,
  title = {The {{Chi-Square Test}}: {{Often Used}} and {{More Often Misinterpreted}}},
  shorttitle = {The {{Chi-Square Test}}},
  author = {Franke, Todd Michael and Ho, Timothy and Christie, Christina A.},
  date = {2012-09},
  journaltitle = {American Journal of Evaluation},
  shortjournal = {American Journal of Evaluation},
  volume = {33},
  number = {3},
  pages = {448--458},
  issn = {1098-2140, 1557-0878},
  doi = {10.1177/1098214011426594},
  url = {http://journals.sagepub.com/doi/10.1177/1098214011426594},
  urldate = {2022-11-01},
  abstract = {The examination of cross-classified category data is common in evaluation and research, with Karl Pearson’s family of chi-square tests representing one of the most utilized statistical analyses for answering questions about the association or difference between categorical variables. Unfortunately, these tests are also among the more commonly misinterpreted statistical tests in the field. The problem is not that researchers and evaluators misapply the results of chi-square tests, but rather they tend to over interpret or incorrectly interpret the results, leading to statements that may have limited or no statistical support based on the analyses preformed.},
  langid = {english},
  keywords = {reading_list},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\F\Franke et al_2012_The Chi-Square Test.pdf}
}

@article{barbantiTransformationModelsIntroduction,
  title = {Transformation {{Models}}: {{An Introduction}} with {{Applications}} in {{R}}},
  author = {Barbanti, Luisa},
  pages = {123},
  langid = {english},
  keywords = {reading_list},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\B\Barbanti_Transformation Models.pdf}
}

@article{molenaar2018PhenotypicSelectionOrnamental,
  title = {Phenotypic {{Selection}} in {{Ornamental Breeding}}: {{It}}'s {{Better}} to {{Have}} the {{BLUPs Than}} to {{Have}} the {{BLUEs}}},
  shorttitle = {Phenotypic {{Selection}} in {{Ornamental Breeding}}},
  author = {Molenaar, Heike and Boehm, Robert and Piepho, Hans-Peter},
  date = {2018-11-05},
  journaltitle = {Frontiers in Plant Science},
  shortjournal = {Front. Plant Sci.},
  volume = {9},
  pages = {1511},
  issn = {1664-462X},
  doi = {10.3389/fpls.2018.01511},
  url = {https://www.frontiersin.org/article/10.3389/fpls.2018.01511/full},
  urldate = {2022-11-01},
  abstract = {Plant breeders always face the challenge to select the best individuals. Selection methods are required that maximize selection gain based on available data. When several crosses have been made, the BLUP procedure achieves this by combining phenotypic data with information on pedigree relationships via an index, known as family-index selection. The index, estimated based on the intra-class correlation coefficient, exploits the relationship among individuals within a family relative to other families in the population. An intra-class correlation coefficient of one indicates that the individual performance can be fully explained based on the family background, whereas an intra-class correlation coefficient of zero indicates the performance of individuals is independent of the family background. In the case the intra-class correlation coefficient is one, family-index selection is considered. In the case the intra-class correlation coefficient is zero, individual selection is considered. The main difference between individual and family-index selection lies in the adjustment in estimating the individual’s effect depending on the intra-class correlation coefficient afforded by the latter. Two examples serve to illustrate the application of the BLUP method. The efficiency of individual and family-index selection was evaluated in terms of the heritability obtained from linear mixed models implementing the selection methods by suitably defining the treatment factor as the sum of individual and family effect. Family-index selection was found to be at least as efficient as individual selection in Dianthus caryophyllus L., except for flower size in standard carnation and vase life in mini carnation for which traits family-index selection outperformed individual selection. Family-index selection was superior to individual selection in Pelargonium zonale in cases when the heritability was low. Hence, the pedigree-based BLUP procedure can enhance selection efficiency in production-related traits in P. zonale or shelf-life related in D. caryophyllus L.},
  langid = {english},
  keywords = {reading_list},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\M\Molenaar et al_2018_Phenotypic Selection in Ornamental Breeding.pdf}
}

@article{piepho2008BLUPPhenotypicSelection,
  title = {{{BLUP}} for Phenotypic Selection in Plant Breeding and Variety Testing},
  author = {Piepho, H. P. and Möhring, J. and Melchinger, A. E. and Büchse, A.},
  date = {2008-05},
  journaltitle = {Euphytica},
  shortjournal = {Euphytica},
  volume = {161},
  number = {1-2},
  pages = {209--228},
  issn = {0014-2336, 1573-5060},
  doi = {10.1007/s10681-007-9449-8},
  url = {https://link.springer.com/10.1007/s10681-007-9449-8},
  urldate = {2022-11-01},
  langid = {english},
  keywords = {reading_list},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\P\Piepho et al_2008_BLUP for phenotypic selection in plant breeding and variety testing.pdf}
}

@article{berger1999IntegratedLikelihoodMethods,
  title = {Integrated Likelihood Methods for Eliminating Nuisance Parameters},
  author = {Berger, James O. and Liseo, Brunero and Wolpert, Robert L.},
  date = {1999-02-01},
  journaltitle = {Statistical Science},
  shortjournal = {Statist. Sci.},
  volume = {14},
  number = {1},
  issn = {0883-4237},
  doi = {10.1214/ss/1009211804},
  url = {https://projecteuclid.org/journals/statistical-science/volume-14/issue-1/Integrated-likelihood-methods-for-eliminating-nuisance-parameters/10.1214/ss/1009211804.full},
  urldate = {2022-11-01},
  abstract = {Elimination of nuisance parameters is a central problem in statistical inference and has been formally studied in virtually all approaches to inference. Perhaps the least studied approach is elimination of nuisance parameters through integration, in the sense that this is viewed as an almost incidental byproduct of Bayesian analysis and is hence not something which is deemed to require separate study. There is, however, considerable value in considering integrated likelihood on its own, especially versions arising from default or noninformative priors. In this paper, we review such common integrated likelihoods and discuss their strengths and weaknesses relative to other methods.},
  langid = {english},
  keywords = {reading_list},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\B\Berger et al_1999_Integrated likelihood methods for eliminating nuisance parameters.pdf}
}

@article{robinson1991ThatBLUPGood,
  title = {That {{BLUP}} Is a {{Good Thing}}: {{The Estimation}} of {{Random Effects}}},
  shorttitle = {That {{BLUP}} Is a {{Good Thing}}},
  author = {Robinson, G. K.},
  date = {1991-02},
  journaltitle = {Statistical Science},
  volume = {6},
  number = {1},
  pages = {15--32},
  publisher = {Institute of Mathematical Statistics},
  issn = {0883-4237, 2168-8745},
  doi = {10.1214/ss/1177011926},
  url = {https://projecteuclid.org/journals/statistical-science/volume-6/issue-1/That-BLUP-is-a-Good-Thing--The-Estimation-of/10.1214/ss/1177011926.full},
  urldate = {2022-11-01},
  abstract = {In animal breeding, Best Linear Unbiased Prediction, or BLUP, is a technique for estimating genetic merits. In general, it is a method of estimating random effects. It can be used to derive the Kalman filter, the method of Kriging used for ore reserve estimation, credibility theory used to work out insurance premiums, and Hoadley's quality measurement plan used to estimate a quality index. It can be used for removing noise from images and for small-area estimation. This paper presents the theory of BLUP, some examples of its application and its relevance to the foundations of statistics. Understanding of procedures for estimating random effects should help people to understand some complicated and controversial issues about fixed and random effects models and also help to bridge the apparent gulf between the Bayesian and Classical schools of thought.},
  keywords = {Best linear unbiased predition (BLUP),credibility theory,estimation of random effects,fixed versus random effects,foundations of statistics,Kalman filtering,likelihood,parametric empirical Bayes methods,Ranking and selection,reading_list,selection index,small-area estimation},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\R\Robinson_1991_That BLUP is a Good Thing.pdf}
}

@book{shaw2014LearnPythonHard,
  title = {Learn {{Python}} the Hard Way: A Very Simple Introduction to the Terrifyingly Beautiful World of Computers and Code},
  shorttitle = {Learn {{Python}} the Hard Way},
  author = {Shaw, Zed},
  date = {2014},
  edition = {Third Edition},
  publisher = {Addison-Wesley},
  location = {Upper Saddle River, NJ},
  isbn = {978-0-321-88491-6},
  langid = {english},
  pagetotal = {287},
  keywords = {Computer programming,Problems exercises etc,Python (Computer program language),reading_list},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\S\Shaw_2014_Learn Python the hard way.pdf}
}

@book{chambers1997StatisticalModels,
  title = {Statistical Models in {{S}}},
  editor = {Chambers, John M.},
  date = {1997},
  series = {Chapman \& {{Hall}} Computer Science Series},
  edition = {Reprint},
  publisher = {Chapman \& Hall},
  location = {London},
  isbn = {978-0-412-83040-2 978-0-412-05291-0 978-0-412-05301-6},
  langid = {english},
  pagetotal = {608},
  keywords = {Book,R,reading_list},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\C\Chambers_1997_Statistical models in S.pdf}
}

@book{stahel2002StatistischeDatenanalyse,
  title = {Statistische Datenanalyse},
  author = {Stahel, Werner A.},
  date = {2002},
  publisher = {Vieweg+Teubner Verlag},
  location = {Wiesbaden},
  doi = {10.1007/978-3-322-96962-0},
  url = {http://link.springer.com/10.1007/978-3-322-96962-0},
  urldate = {2022-11-01},
  isbn = {978-3-528-36653-7 978-3-322-96962-0},
  langid = {ngerman},
  keywords = {Book,Stat},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\S\Stahel_2002_Statistische Datenanalyse.pdf}
}

@book{oehlert2000FirstCourseDesign,
  title = {A First Course in Design and Analysis of Experiments},
  author = {Oehlert, Gary W.},
  date = {2000},
  publisher = {W.H. Freeman},
  location = {New York},
  isbn = {978-0-7167-3510-6},
  langid = {english},
  pagetotal = {659},
  keywords = {Book,Experimental design,Stat},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\O\Oehlert_2000_A first course in design and analysis of experiments.pdf}
}

@book{dunn2018GeneralizedLinearModels,
  title = {Generalized {{Linear Models With Examples}} in {{R}}},
  author = {Dunn, Peter K. and Smyth, Gordon K.},
  date = {2018},
  series = {Springer {{Texts}} in {{Statistics}}},
  publisher = {Springer New York},
  location = {New York, NY},
  doi = {10.1007/978-1-4419-0118-7},
  url = {http://link.springer.com/10.1007/978-1-4419-0118-7},
  urldate = {2022-11-01},
  isbn = {978-1-4419-0117-0 978-1-4419-0118-7},
  langid = {english},
  keywords = {Book,Stat},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\D\Dunn_Smyth_2018_Generalized Linear Models With Examples in R.pdf}
}

@book{bates1988NonlinearRegressionAnalysis,
  title = {Nonlinear Regression Analysis and Its Applications},
  author = {Bates, Douglas M. and Watts, Donald G.},
  date = {1988},
  series = {Wiley Series in Probability and Mathematical Statistics},
  publisher = {Wiley},
  location = {New York},
  isbn = {978-0-471-81643-0},
  langid = {english},
  pagetotal = {365},
  keywords = {Book,Linear models (Statistics),Parameter estimation,Regression analysis,Stat},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\B\Bates_Watts_1988_Nonlinear regression analysis and its applications.pdf}
}

@book{bivand2013AppliedSpatialData,
  title = {Applied {{Spatial Data Analysis}} with {{R}}},
  author = {Bivand, Roger S. and Pebesma, Edzer and Gómez-Rubio, Virgilio},
  date = {2013},
  publisher = {Springer New York},
  location = {New York, NY},
  doi = {10.1007/978-1-4614-7618-4},
  url = {http://link.springer.com/10.1007/978-1-4614-7618-4},
  urldate = {2022-11-01},
  isbn = {978-1-4614-7617-7 978-1-4614-7618-4},
  langid = {english},
  keywords = {Book,Stat},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\B\Bivand et al_2013_Applied Spatial Data Analysis with R.pdf}
}

@book{dalgaard2008IntroductoryStatistics,
  title = {Introductory {{Statistics}} with {{R}}},
  author = {Dalgaard, Peter},
  date = {2008},
  series = {Statistics and {{Computing}}},
  publisher = {Springer New York},
  location = {New York, NY},
  doi = {10.1007/978-0-387-79054-1},
  url = {http://link.springer.com/10.1007/978-0-387-79054-1},
  urldate = {2022-11-01},
  isbn = {978-0-387-79053-4 978-0-387-79054-1},
  langid = {english},
  keywords = {Book,Stat},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\D\Dalgaard_2008_Introductory Statistics with R.pdf}
}

@book{diggle2007ModelbasedGeostatistics,
  title = {Model-Based Geostatistics},
  author = {Diggle, Peter and Ribeiro, Paulo J.},
  date = {2007},
  series = {Springer Series in Statistics},
  publisher = {Springer},
  location = {New York, NY},
  isbn = {978-0-387-32907-9},
  langid = {english},
  pagetotal = {228},
  keywords = {Book,Geology,Mathematical models,Stat,Statistical methods},
  annotation = {OCLC: ocm71284654},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\D\Diggle_Ribeiro_2007_Model-based geostatistics.pdf}
}

@book{everitt2011IntroductionAppliedMultivariate,
  title = {An {{Introduction}} to {{Applied Multivariate Analysis}} with {{R}}},
  author = {Everitt, Brian and Hothorn, Torsten},
  date = {2011},
  publisher = {Springer New York},
  location = {New York, NY},
  doi = {10.1007/978-1-4419-9650-3},
  url = {http://link.springer.com/10.1007/978-1-4419-9650-3},
  urldate = {2022-11-01},
  isbn = {978-1-4419-9649-7 978-1-4419-9650-3},
  langid = {english},
  keywords = {Book,Stat},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\E\Everitt_Hothorn_2011_An Introduction to Applied Multivariate Analysis with R.pdf}
}

@article{gelmanBayesianDataAnalysis,
  title = {Bayesian {{Data Analysis Third}} Edition (with Errors Fixed as of 13 {{February}} 2020)},
  author = {Gelman, Andrew and Carlin, John B and Stern, Hal S and Dunson, David B and Vehtari, Aki and Rubin, Donald B},
  pages = {677},
  langid = {english},
  keywords = {Book,Stat},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\G\Gelman et al_Bayesian Data Analysis Third edition (with errors ﬁxed as of 13 February 2020).pdf}
}

@book{hastie2009ElementsStatisticalLearning,
  title = {The {{Elements}} of {{Statistical Learning}}},
  author = {Hastie, Trevor and Tibshirani, Robert and Friedman, Jerome},
  date = {2009},
  series = {Springer {{Series}} in {{Statistics}}},
  publisher = {Springer New York},
  location = {New York, NY},
  doi = {10.1007/978-0-387-84858-7},
  url = {http://link.springer.com/10.1007/978-0-387-84858-7},
  urldate = {2022-11-01},
  isbn = {978-0-387-84857-0 978-0-387-84858-7},
  langid = {english},
  keywords = {Book,Stat},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\H\Hastie et al_2009_The Elements of Statistical Learning.pdf}
}

@book{james2013IntroductionStatisticalLearning,
  title = {An {{Introduction}} to {{Statistical Learning}}},
  author = {James, Gareth and Witten, Daniela and Hastie, Trevor and Tibshirani, Robert},
  date = {2013},
  series = {Springer {{Texts}} in {{Statistics}}},
  volume = {103},
  publisher = {Springer New York},
  location = {New York, NY},
  doi = {10.1007/978-1-4614-7138-7},
  url = {http://link.springer.com/10.1007/978-1-4614-7138-7},
  urldate = {2022-11-01},
  isbn = {978-1-4614-7137-0 978-1-4614-7138-7},
  langid = {english},
  keywords = {Book,Stat},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\J\James et al_2013_An Introduction to Statistical Learning.pdf}
}

@book{murphy2012MachineLearningProbabilistic,
  title = {Machine Learning: A Probabilistic Perspective},
  shorttitle = {Machine Learning},
  author = {Murphy, Kevin P.},
  date = {2012},
  series = {Adaptive Computation and Machine Learning Series},
  publisher = {MIT Press},
  location = {Cambridge, MA},
  isbn = {978-0-262-01802-9},
  langid = {english},
  pagetotal = {1067},
  keywords = {Book,Machine learning,Probabilities,Stat},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\M\Murphy_2012_Machine learning.pdf}
}

@book{koenker2005QuantileRegression,
  title = {Quantile {{Regression}}},
  author = {Koenker, Roger},
  date = {2005},
  series = {Econometric {{Society Monographs}}},
  publisher = {Cambridge University Press},
  location = {Cambridge},
  doi = {10.1017/CBO9780511754098},
  url = {https://www.cambridge.org/core/books/quantile-regression/C18AE7BCF3EC43C16937390D44A328B1},
  urldate = {2022-11-01},
  abstract = {Quantile regression is gradually emerging as a unified statistical methodology for estimating models of conditional quantile functions. By complementing the exclusive focus of classical least squares regression on the conditional mean, quantile regression offers a systematic strategy for examining how covariates influence the location, scale and shape of the entire response distribution. This monograph is the first comprehensive treatment of the subject, encompassing models that are linear and nonlinear, parametric and nonparametric. The author has devoted more than 25 years of research to this topic. The methods in the analysis are illustrated with a variety of applications from economics, biology, ecology and finance. The treatment will find its core audiences in econometrics, statistics, and applied mathematics in addition to the disciplines cited above.},
  isbn = {978-0-521-84573-1},
  keywords = {Book,Stat},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\K\Koenker_2005_Quantile Regression.pdf}
}

@book{bates2018Lme4MixedeffectsModeling,
  title = {Lme4: {{Mixed-effects}} Modeling with {{R}}},
  author = {Bates, Douglas M.},
  date = {2018},
  keywords = {Book,Stat},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\B\Bates_2018_lme4.pdf}
}

@book{moran2012PrinciplesBiochemistry,
  title = {Principles of Biochemistry},
  editor = {Moran, Laurence A.},
  date = {2012},
  edition = {5th ed},
  publisher = {Pearson},
  location = {Boston},
  isbn = {978-0-321-70733-8},
  pagetotal = {786},
  keywords = {Biochemistry},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\M\Moran_2012_Principles of biochemistry.pdf}
}

@book{mortimer2020ChemieBasiswissenChemie,
  title = {Chemie: Das Basiswissen der Chemie},
  shorttitle = {Chemie},
  author = {Mortimer, Charles E. and Müller, Ulrich},
  date = {2020},
  edition = {13},
  pages = {b-006-163279},
  publisher = {Georg Thieme Verlag},
  location = {Stuttgart},
  doi = {10.1055/b-006-163279},
  url = {https://eref.thieme.de/10.1055/b-006-163279},
  urldate = {2022-11-01},
  isbn = {978-3-13-242274-2 978-3-13-242276-6},
  langid = {ngerman},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\M\Mortimer_Müller_2020_Chemie.pdf}
}

@book{searle1992VarianceComponents,
  title = {Variance {{Components}}},
  author = {Searle, Shayle R. and Casella, George and McCulloch, Charles E.},
  date = {1992},
  publisher = {John Wiley \& Sons, Ltd},
  doi = {10.1002/9780470316856.fmatter},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/9780470316856.fmatter},
  urldate = {2022-11-01},
  abstract = {The prelims comprise: Half Title Title Copyright Preface Contents},
  isbn = {978-0-470-31685-6},
  langid = {english},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\S\Searle et al_1992_Variance Components.pdf}
}

@article{raghavaraoChoiceBasedConjointAnalysis,
  title = {Choice-{{Based Conjoint Analysis}}},
  author = {Raghavarao, Damaraju and Wiley, James B and Chitturi, Pallavi},
  pages = {190},
  langid = {english},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\R\Raghavarao et al_Choice-Based Conjoint Analysis.pdf}
}

@book{rao2014AppliedConjointAnalysis,
  title = {Applied {{Conjoint Analysis}}},
  author = {Rao, Vithala R.},
  date = {2014},
  publisher = {Springer Berlin Heidelberg},
  location = {Berlin, Heidelberg},
  doi = {10.1007/978-3-540-87753-0},
  url = {http://link.springer.com/10.1007/978-3-540-87753-0},
  urldate = {2022-11-01},
  isbn = {978-3-540-87752-3 978-3-540-87753-0},
  langid = {english},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\R\Rao_2014_Applied Conjoint Analysis.pdf}
}

@book{gustafsson2007ConjointMeasurement,
  title = {Conjoint {{Measurement}}},
  editor = {Gustafsson, Anders and Herrmann, Andreas and Huber, Frank},
  date = {2007},
  publisher = {Springer},
  location = {Berlin, Heidelberg},
  doi = {10.1007/978-3-540-71404-0},
  url = {http://link.springer.com/10.1007/978-3-540-71404-0},
  urldate = {2022-11-01},
  isbn = {978-3-540-71403-3 978-3-540-71404-0},
  langid = {english},
  keywords = {calculus,design,development,e-learning,Evaluation,game theory,Mapping,Market research,marketing,modeling,optimization,preference measurement,Sales,Simulation,utility theory},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\G\Gustafsson et al_2007_Conjoint Measurement.pdf}
}

@book{buhlmann2011StatisticsHighDimensionalData,
  title = {Statistics for {{High-Dimensional Data}}},
  author = {Bühlmann, Peter and family=Geer, given=Sara, prefix=van de, useprefix=true},
  date = {2011},
  series = {Springer {{Series}} in {{Statistics}}},
  publisher = {Springer Berlin Heidelberg},
  location = {Berlin, Heidelberg},
  doi = {10.1007/978-3-642-20192-9},
  url = {http://link.springer.com/10.1007/978-3-642-20192-9},
  urldate = {2022-11-01},
  isbn = {978-3-642-20191-2 978-3-642-20192-9},
  langid = {english},
  keywords = {Book,Stat},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\B\Bühlmann_van de Geer_2011_Statistics for High-Dimensional Data.pdf}
}

@article{westLinearMixedModels,
  title = {Linear {{Mixed Models}}},
  author = {West, Brady T},
  pages = {430},
  langid = {english},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\W\West_Linear Mixed Models.pdf}
}

@book{zuur2009MixedEffectsModels,
  title = {Mixed Effects Models and Extensions in Ecology with {{R}}},
  author = {Zuur, Alain F. and Ieno, Elena N. and Walker, Neil and Saveliev, Anatoly A. and Smith, Graham M.},
  date = {2009},
  series = {Statistics for {{Biology}} and {{Health}}},
  publisher = {Springer New York},
  location = {New York, NY},
  doi = {10.1007/978-0-387-87458-6},
  url = {http://link.springer.com/10.1007/978-0-387-87458-6},
  urldate = {2022-11-01},
  isbn = {978-0-387-87457-9 978-0-387-87458-6},
  langid = {english},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\Z\Zuur et al_2009_Mixed effects models and extensions in ecology with R.pdf}
}

@book{jiang2007LinearGeneralizedLinear,
  title = {Linear and Generalized Linear Mixed Models and Their Applications},
  author = {Jiang, Jiming},
  date = {2007},
  series = {Springer Series in Statistics},
  publisher = {Springer},
  location = {New York ; London},
  isbn = {978-0-387-47941-5 978-0-387-47946-0},
  langid = {english},
  pagetotal = {257},
  keywords = {Linear models (Statistics),Mathematical statistics},
  annotation = {OCLC: ocm77256604},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\J\Jiang_2007_Linear and generalized linear mixed models and their applications.pdf}
}

@book{jiang2021LinearGeneralizedLinear,
  title = {Linear and {{Generalized Linear Mixed Models}} and {{Their Applications}}},
  author = {Jiang, Jiming and Nguyen, Thuan},
  date = {2021},
  series = {Springer {{Series}} in {{Statistics}}},
  publisher = {Springer New York},
  location = {New York, NY},
  doi = {10.1007/978-1-0716-1282-8},
  url = {https://link.springer.com/10.1007/978-1-0716-1282-8},
  urldate = {2022-11-01},
  isbn = {978-1-07-161281-1 978-1-07-161282-8},
  langid = {english},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\J\Jiang_Nguyen_2021_Linear and Generalized Linear Mixed Models and Their Applications.pdf}
}

@book{pinheiro2000MixedEffectsModelsSPLUS,
  title = {Mixed-{{Effects Models}} in {{S}} and {{S-PLUS}}},
  author = {Pinheiro, Jose C. and Bates, Douglas M.},
  date = {2000},
  url = {https://link.springer.com/book/10.1007/b98882},
  urldate = {2022-11-01},
  langid = {english},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\P\Pinheiro_Bates_2000_Mixed-Effects Models in S and S-PLUS.pdf}
}

@book{chacon2014ProGit,
  title = {Pro {{Git}}},
  author = {Chacon, Scott and Straub, Ben},
  date = {2014},
  publisher = {Apress},
  location = {Berkeley, CA},
  doi = {10.1007/978-1-4842-0076-6},
  url = {http://link.springer.com/10.1007/978-1-4842-0076-6},
  urldate = {2022-11-01},
  isbn = {978-1-4842-0077-3 978-1-4842-0076-6},
  langid = {english},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\C\Chacon_Straub_2014_Pro Git.pdf}
}

@article{montgomery2017DesignAnalysisExperiments,
  title = {Design and {{Analysis}} of {{Experiments}}},
  author = {Montgomery, Douglas C},
  date = {2017},
  pages = {749},
  langid = {english},
  keywords = {Book,Stat},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\M\Montgomery_2017_Design and Analysis of Experiments.pdf}
}

@book{chernick2011IntroductionBootstrapMethods,
  title = {An {{Introduction}} to {{Bootstrap Methods}} with {{Applications}} to {{R}}},
  author = {Chernick, Michael R},
  date = {2011},
  langid = {english},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\C\Chernick_2011_An Introduction to Bootstrap Methods with Applications to R.pdf}
}

@book{meier2020WahrscheinlichkeitsrechnungUndStatistik,
  title = {Wahrscheinlichkeitsrechnung und Statistik: Eine Einführung für Verständnis, Intuition und Überblick},
  shorttitle = {Wahrscheinlichkeitsrechnung und Statistik},
  author = {Meier, Lukas},
  date = {2020},
  publisher = {Springer Berlin Heidelberg},
  location = {Berlin, Heidelberg},
  doi = {10.1007/978-3-662-61488-4},
  url = {http://link.springer.com/10.1007/978-3-662-61488-4},
  urldate = {2022-11-01},
  isbn = {978-3-662-61487-7 978-3-662-61488-4},
  langid = {ngerman},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\M\Meier_2020_Wahrscheinlichkeitsrechnung und Statistik.pdf}
}

@book{kalisch2021LogistischeRegressionAnwendungsorientierte,
  title = {Logistische Regression: Eine anwendungsorientierte Einführung mit R},
  shorttitle = {Logistische Regression},
  author = {Kalisch, Markus and Meier, Lukas},
  date = {2021},
  series = {essentials},
  publisher = {Springer Fachmedien Wiesbaden},
  location = {Wiesbaden},
  doi = {10.1007/978-3-658-34225-8},
  url = {https://link.springer.com/10.1007/978-3-658-34225-8},
  urldate = {2022-11-01},
  isbn = {978-3-658-34224-1 978-3-658-34225-8},
  langid = {ngerman},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\K\Kalisch_Meier_2021_Logistische Regression.pdf}
}

@article{bretz2011MultipleComparisonsUsing,
  title = {Multiple {{Comparisons Using R}}},
  author = {Bretz, Frank and Hothorn, Torsten and Westfall, Peter},
  date = {2011},
  pages = {202},
  langid = {english},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\B\Bretz et al_2011_Multiple Comparisons Using R.pdf}
}

@book{daley2003IntroductionTheoryPoint,
  title = {An Introduction to the Theory of Point Processes},
  author = {Daley, Daryl J. and Vere-Jones, D.},
  date = {2003},
  edition = {2nd ed},
  publisher = {Springer},
  location = {New York},
  isbn = {978-0-387-95541-4 978-0-387-21337-8 978-0-387-49835-5},
  langid = {english},
  pagetotal = {2},
  keywords = {Point processes},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\D\Daley_Vere-Jones_2003_An introduction to the theory of point processes.pdf}
}

@article{faraway2016ExtendingLinearModel,
  title = {Extending the {{Linear Model}} with {{R}}},
  author = {Faraway, Julian J},
  date = {2016},
  pages = {411},
  langid = {english},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\F\Faraway_2016_Extending the Linear Model with R.pdf}
}

@book{field2012DiscoveringStatisticsUsing,
  title = {Discovering Statistics Using {{R}}},
  author = {Field, Andy P. and Miles, Jeremy and Field, Zoë},
  date = {2012},
  publisher = {Sage},
  location = {London ; Thousand Oaks, Calif},
  isbn = {978-1-4462-0046-9 978-1-4462-0045-2},
  langid = {english},
  pagetotal = {957},
  keywords = {Computer programs,R (Computer program language),Social sciences,Statistical methods Computer programs,Statistics},
  annotation = {OCLC: ocn760970657},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\F\Field et al_2012_Discovering statistics using R.pdf}
}

@book{filzmoser2018AppliedCompositionalData,
  title = {Applied {{Compositional Data Analysis}}: {{With Worked Examples}} in {{R}}},
  shorttitle = {Applied {{Compositional Data Analysis}}},
  author = {Filzmoser, Peter and Hron, Karel and Templ, Matthias},
  date = {2018},
  series = {Springer {{Series}} in {{Statistics}}},
  publisher = {Springer International Publishing},
  location = {Cham},
  doi = {10.1007/978-3-319-96422-5},
  url = {http://link.springer.com/10.1007/978-3-319-96422-5},
  urldate = {2022-11-01},
  isbn = {978-3-319-96420-1 978-3-319-96422-5},
  langid = {english},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\F\Filzmoser et al_2018_Applied Compositional Data Analysis.pdf}
}

@book{hahn1991StatisticalIntervalsGuide,
  title = {Statistical Intervals: A Guide for Practitioners},
  shorttitle = {Statistical Intervals},
  author = {Hahn, Gerald J. and Meeker, William Q.},
  date = {1991},
  series = {Wiley Series in Probability and Mathematical Statistics},
  publisher = {Wiley},
  location = {New York},
  isbn = {978-0-471-88769-0},
  langid = {english},
  pagetotal = {392},
  keywords = {Mathematical statistics},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\H\Hahn_Meeker_1991_Statistical intervals.pdf}
}

@article{husson2017ExploratoryMultivariateAnalysis,
  title = {Exploratory {{Multivariate Analysis}} by {{Example Using R}}},
  author = {Husson, Francois and Le, Sebastien and Pagès, Jérôme},
  date = {2017},
  pages = {263},
  langid = {english},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\H\Husson et al_2017_Exploratory Multivariate Analysis by Example Using R.pdf}
}

@article{jones2015DesignAnalysisCrossOver,
  title = {Design and {{Analysis}} of {{Cross-Over Trials}}},
  author = {Jones, Byron and Kenward, Michael G},
  date = {2015},
  pages = {431},
  langid = {english},
  keywords = {Book,Stat},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\J\Jones_Kenward_2015_Design and Analysis of Cross-Over Trials.pdf}
}

@article{kendall1961AdvancedTheoryStatistics,
  title = {The {{Advanced Theory}} of {{Statistics}}},
  author = {Kendall, Maurice G.},
  date = {1961},
  pages = {684},
  langid = {english},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\K\Kendall_1961_The Advanced Theory of Statistics.pdf}
}

@book{maronna2019RobustStatisticsTheory,
  title = {Robust Statistics: Theory and Methods (with {{R}})},
  shorttitle = {Robust Statistics},
  author = {Maronna, Ricardo A.},
  date = {2019},
  series = {Wiley Series in Probability and Statistics},
  edition = {Second edition},
  publisher = {WIley},
  location = {Hoboken, NJ},
  isbn = {978-1-119-21467-0 978-1-119-21466-3},
  langid = {english},
  pagetotal = {1},
  keywords = {Robust statistics},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\M\Maronna_2019_Robust statistics.pdf}
}

@book{mcelreath2020StatisticalRethinkingBayesian,
  title = {Statistical Rethinking: A {{Bayesian}} Course with Examples in {{R}} and {{Stan}}},
  shorttitle = {Statistical Rethinking},
  author = {McElreath, Richard},
  date = {2020},
  series = {{{CRC}} Texts in Statistical Science},
  edition = {2},
  publisher = {{Taylor and Francis, CRC Press}},
  location = {Boca Raton},
  abstract = {"Statistical Rethinking: A Bayesian Course with Examples in R and Stan, Second Edition builds knowledge/confidence in statistical modeling. Pushes readers to perform step-by-step calculations (usually automated.) Unique, computational approach ensures readers understand details to make reasonable choices and interpretations in their modeling work"--},
  isbn = {978-0-367-13991-9},
  langid = {english},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\M\McElreath_2020_Statistical rethinking.pdf}
}

@article{shanmugam2018ElementsCausalInference,
  title = {Elements of Causal Inference: Foundations and Learning Algorithms},
  shorttitle = {Elements of Causal Inference},
  author = {Shanmugam, Ramalingam},
  date = {2018-11-02},
  journaltitle = {Journal of Statistical Computation and Simulation},
  shortjournal = {Journal of Statistical Computation and Simulation},
  volume = {88},
  number = {16},
  pages = {3248--3248},
  issn = {0094-9655, 1563-5163},
  doi = {10.1080/00949655.2018.1505197},
  url = {https://www.tandfonline.com/doi/full/10.1080/00949655.2018.1505197},
  urldate = {2022-11-01},
  langid = {english}
}

@book{shumway2017TimeSeriesAnalysis,
  title = {Time {{Series Analysis}} and {{Its Applications}}: {{With R Examples}}},
  shorttitle = {Time {{Series Analysis}} and {{Its Applications}}},
  author = {Shumway, Robert H. and Stoffer, David S.},
  date = {2017},
  series = {Springer {{Texts}} in {{Statistics}}},
  publisher = {Springer International Publishing},
  location = {Cham},
  doi = {10.1007/978-3-319-52452-8},
  url = {http://link.springer.com/10.1007/978-3-319-52452-8},
  urldate = {2022-11-01},
  isbn = {978-3-319-52451-1 978-3-319-52452-8},
  langid = {english},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\S\Shumway_Stoffer_2017_Time Series Analysis and Its Applications.pdf}
}

@book{vandenboogaart2013AnalyzingCompositionalData,
  title = {Analyzing {{Compositional Data}} with {{R}}},
  author = {family=Boogaart, given=K. Gerald, prefix=van den, useprefix=true and Tolosana-Delgado, Raimon},
  date = {2013},
  publisher = {Springer Berlin Heidelberg},
  location = {Berlin, Heidelberg},
  doi = {10.1007/978-3-642-36809-7},
  url = {http://link.springer.com/10.1007/978-3-642-36809-7},
  urldate = {2022-11-01},
  isbn = {978-3-642-36808-0 978-3-642-36809-7},
  langid = {english},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\V\van den Boogaart_Tolosana-Delgado_2013_Analyzing Compositional Data with R.pdf}
}

@book{venables2002ModernAppliedStatistics,
  title = {Modern {{Applied Statistics}} with {{S}}},
  author = {Venables, W. N. and Ripley, B. D.},
  editor = {Chambers, J. and Eddy, W. and Härdle, W. and Sheather, S. and Tierney, L.},
  editortype = {redactor},
  date = {2002},
  series = {Statistics and {{Computing}}},
  publisher = {Springer New York},
  location = {New York, NY},
  doi = {10.1007/978-0-387-21706-2},
  url = {http://link.springer.com/10.1007/978-0-387-21706-2},
  urldate = {2022-11-01},
  isbn = {978-1-4419-3008-8 978-0-387-21706-2},
  langid = {english},
  keywords = {Book,R,reading_list},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\V\Venables_Ripley_2002_Modern Applied Statistics with S.pdf}
}

@book{agresti2013CategoricalDataAnalysis,
  title = {Categorical {{Data Analysis}}},
  author = {Agresti, Alan},
  date = {2013},
  edition = {3},
  url = {https://www.wiley.com/en-us/Categorical+Data+Analysis%2C+3rd+Edition-p-9780470463635},
  urldate = {2022-11-01},
  langid = {american},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\A\Agresti_2013_Categorical Data Analysis.pdf}
}

@book{conover1999PracticalNonparametricStatistics,
  title = {Practical Nonparametric Statistics},
  author = {Conover, W. J.},
  date = {1999-12-14},
  edition = {3rd Edition},
  publisher = {Wiley},
  location = {New York},
  isbn = {978-0-471-16068-7},
  langid = {Englisch},
  pagetotal = {584},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\C\Conover_1999_Practical Nonparametric Statistics.pdf}
}

@book{faraway2014LinearModels,
  title = {Linear Models with R},
  author = {Faraway, Julian J.},
  date = {2014-07-01},
  edition = {2},
  publisher = {{Chapman and Hall/CRC}},
  location = {Boca Raton},
  isbn = {978-1-4398-8733-2},
  langid = {Englisch},
  pagetotal = {286},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\F\Faraway_2014_Linear Models with R.pdf}
}

@book{pearl2009CausalityModelsReasoning,
  title = {Causality: Models, Reasoning and Inference},
  shorttitle = {Causality},
  author = {Pearl, Judea},
  date = {2009-09-14},
  edition = {2nd Edition},
  publisher = {Cambridge University Press},
  location = {Cambridge, U.K. ; New York},
  isbn = {978-0-521-89560-6},
  langid = {Englisch},
  pagetotal = {484},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\P\Pearl_2009_Causality.pdf}
}

@incollection{russell1999HypothesisTestingLinear,
  title = {Hypothesis {{Testing}} in {{Linear Regression Models}}},
  author = {Russell, Davidson and MacKinnon, James G.},
  date = {1999},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\R\Russell_MacKinnon_1999_Hypothesis Testing in Linear Regression Models.pdf}
}

@article{pedersen2019HierarchicalGeneralizedAdditive,
  title = {Hierarchical Generalized Additive Models in Ecology: An Introduction with Mgcv},
  shorttitle = {Hierarchical Generalized Additive Models in Ecology},
  author = {Pedersen, Eric J. and Miller, David L. and Simpson, Gavin L. and Ross, Noam},
  date = {2019-05-27},
  journaltitle = {PeerJ},
  shortjournal = {PeerJ},
  volume = {7},
  pages = {e6876},
  publisher = {PeerJ Inc.},
  issn = {2167-8359},
  doi = {10.7717/peerj.6876},
  url = {https://peerj.com/articles/6876},
  urldate = {2022-11-09},
  abstract = {In this paper, we discuss an extension to two popular approaches to modeling complex structures in ecological data: the generalized additive model (GAM) and the hierarchical model (HGLM). The hierarchical GAM (HGAM), allows modeling of nonlinear functional relationships between covariates and outcomes where the shape of the function itself varies between different grouping levels. We describe the theoretical connection between HGAMs, HGLMs, and GAMs, explain how to model different assumptions about the degree of intergroup variability in functional response, and show how HGAMs can be readily fitted using existing GAM software, the mgcv package in R. We also discuss computational and statistical issues with fitting these models, and demonstrate how to fit HGAMs on example data. All code and data used to generate this paper are available at: github.com/eric-pedersen/mixed-effect-gams.},
  langid = {english},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\P\Pedersen et al_2019_Hierarchical generalized additive models in ecology.pdf}
}

@article{viechtbauer2010ConductingMetaAnalysesMetafor,
  title = {Conducting {{Meta-Analyses}} in {{R}} with the Metafor {{Package}}},
  author = {Viechtbauer, Wolfgang},
  date = {2010-08-05},
  journaltitle = {Journal of Statistical Software},
  volume = {36},
  pages = {1--48},
  issn = {1548-7660},
  doi = {10.18637/jss.v036.i03},
  url = {https://doi.org/10.18637/jss.v036.i03},
  urldate = {2022-11-09},
  abstract = {The metafor package provides functions for conducting meta-analyses in R. The package includes functions for fitting the meta-analytic fixed- and random-effects models and allows for the inclusion of moderators variables (study-level covariates) in these models. Meta-regression analyses with continuous and categorical moderators can be conducted in this way.  Functions for the Mantel-Haenszel and Peto's one-step method for meta-analyses of 2 x 2 table data are also available. Finally, the package provides various plot functions (for example, for forest, funnel, and radial plots) and functions for assessing the model fit, for obtaining case diagnostics, and for tests of publication bias.},
  langid = {english},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\V\Viechtbauer_2010_Conducting Meta-Analyses in R with the metafor Package.pdf}
}

@article{schreiber2023LongitudinalIncreaseDetection,
  title = {Longitudinal Increase in the Detection Rate of {{Mycobacterium}} Chimaera in Heater-Cooler Device-Derived Water Samples},
  author = {Schreiber, P.W. and Zihlmann, R. and Schärer, V. and Hasse, B. and Imkamp, F. and Schulthess, B. and Sander, P. and Zingg, W.},
  date = {2023-01},
  journaltitle = {Journal of Hospital Infection},
  shortjournal = {Journal of Hospital Infection},
  volume = {131},
  pages = {190--193},
  issn = {01956701},
  doi = {10.1016/j.jhin.2022.11.003},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0195670122003553},
  urldate = {2022-12-27},
  abstract = {Background: Colonization with Mycobacterium chimaera and other non-tuberculous mycobacteria (NTM) has been reported for heater-cooler devices (HCDs) produced by several manufacturers. Up until now, exclusively LivaNova (London, UK) HCDs have been associated with M. chimaera infections after cardiac surgery. The vast majority of studies on HCD colonization were cross-sectional. The vast majority of studies on HCD colonization were cross-sectional. Aim: We were interested in longitudinal dynamics of mycobacterial growth in HCD water samples and analysed data of a prospective mycobacterial surveillance of five LivaNova 3T HCDs. Methods: Five LivaNova HCDs were subjected to prospective mycobacterial surveillance. For each HCD and the total of HCDs, results of mycobacterial detection were analyzed. Logistic regression was applied to model the association between growth of any NTM or M. chimaera and duration of HCD use. Results: Non-tuberculous mycobacteria were isolated in 319 (48.0\%, 21 water samples grew more than one mycobacterial species) of a total of 665 water samples. The most frequently detected species were M. chimaera (N ¼ 247/319, 77.4\%), Mycobacterium gordonae (46/319, 14.4\%) and Mycobacterium paragordonae (34/319, 10.7\%). Detection rates increased prospectively for any NTM (odds ratio (OR) per year in use: 1.60, 95\% confidence interval (CI) 1.17e2.24, P{$<$}0.001) and for M. chimaera (OR per year in use: 1.67, 95\% CI 1.11e2.57, P{$<$}0.01). Conclusion: Longer duration of HCD use was associated with higher detection rates for any NTM and M. chimaera, respectively.},
  langid = {english},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\S\Schreiber et al_2023_Longitudinal increase in the detection rate of Mycobacterium chimaera in.pdf}
}

@book{fox2019CompanionAppliedRegression,
  title = {An {{R}} Companion to Applied Regression},
  author = {Fox, John and Weisberg, Sanford},
  date = {2019},
  edition = {Third edition},
  publisher = {SAGE},
  location = {Los Angeles},
  isbn = {978-1-5443-3647-3},
  langid = {english},
  pagetotal = {577},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\F\Fox_Weisberg_2019_An R companion to applied regression.pdf}
}

@book{fox2016AppliedRegressionAnalysis,
  title = {Applied Regression Analysis and Generalized Linear Models},
  author = {Fox, John and Fox, John},
  date = {2016},
  edition = {Third Edition},
  publisher = {SAGE},
  location = {Los Angeles},
  isbn = {978-1-4522-0566-3},
  langid = {english},
  pagetotal = {791},
  annotation = {OCLC: ocn894301740},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\F\Fox_Fox_2016_Applied regression analysis and generalized linear models.pdf}
}

@book{fox2020RegressionDiagnosticsIntroduction,
  title = {Regression Diagnostics: An Introduction},
  shorttitle = {Regression Diagnostics},
  author = {Fox, John},
  date = {2020},
  series = {Quantitative Applications in the Social Sciences},
  edition = {Second edition},
  number = {79},
  publisher = {SAGE Publications, Inc},
  location = {Thousand Oaks, California},
  abstract = {"Regression diagnostics are methods for determining whether a regression model that has been fit to data adequately represents the structure of the data. For example, if the model assumes a linear (straight-line) relationship between the response and an explanatory variable, is the assumption of linearity warranted? Regression diagnostics not only reveal deficiencies in a regression model that has been fit to data but in many instances may suggest how the model can be improved. The Second Edition of this bestselling volume by John Fox considers two important classes of regression models: the normal linear regression model (LM), in which the response variable is quantitative and assumed to have a normal distribution conditional on the values of the explanatory variables; and generalized linear models (GLMs) in which the conditional distribution of the response variable is a member of an exponential family. R code for examples within the text can be found on an accompanying website"--},
  isbn = {978-1-5443-7522-9},
  pagetotal = {151},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\F\Fox_2020_Regression diagnostics.pdf}
}

@book{wood2015CoreStatistics,
  title = {Core Statistics},
  author = {Wood, Simon N.},
  date = {2015},
  series = {Institute of {{Mathematical Statistics}} Textbooks},
  number = {6},
  publisher = {Cambridge University Press},
  location = {New York, NY},
  isbn = {978-1-107-41504-1 978-1-107-07105-6},
  langid = {english},
  pagetotal = {250},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\W\Wood_2015_Core statistics.pdf}
}

@article{batesLmerSASPROC,
  title = {Lmer for {{SAS PROC MIXED Users}}},
  author = {Bates, Douglas},
  langid = {english},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\B\Bates_lmer for SAS PROC MIXED Users.pdf}
}

@article{voelkl2020ReproducibilityAnimalResearch,
  title = {Reproducibility of Animal Research in Light of Biological Variation},
  author = {Voelkl, Bernhard and Altman, Naomi S. and Forsman, Anders and Forstmeier, Wolfgang and Gurevitch, Jessica and Jaric, Ivana and Karp, Natasha A. and Kas, Martien J. and Schielzeth, Holger and Van de Casteele, Tom and Würbel, Hanno},
  date = {2020-07-15},
  journaltitle = {Nature Reviews Neuroscience},
  shortjournal = {Nat Rev Neurosci},
  volume = {21},
  number = {7},
  pages = {384--393},
  issn = {1471-003X, 1471-0048},
  doi = {10.1038/s41583-020-0313-3},
  url = {https://www.nature.com/articles/s41583-020-0313-3},
  urldate = {2023-06-15},
  abstract = {Context-d ependent biological variation presents a unique challenge to the reproducibility of results in experimental animal research, because organisms’ responses to experimental treatments can vary with both genotype and environmental conditions. In March 2019, experts in animal biology, experimental design and statistics convened in Blonay, Switzerland, to discuss strategies addressing this challenge. In contrast to the current gold standard of rigorous standardization in experimental animal research, we recommend the use of systematic heterogenization of study samples and conditions by actively incorporating biological variation into study design through diversifying study samples and conditions. Here we provide the scientific rationale for this approach in the hope that researchers, regulators, funders and editors can embrace this paradigm shift. We also present a road map towards better practices in view of improving the reproducibility of animal research.},
  langid = {english},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\V\Voelkl et al_2020_Reproducibility of animal research in light of biological variation.pdf}
}

@book{kaltenbach2021StatisticalDesignAnalysis,
  title = {Statistical {{Design}} and {{Analysis}} of {{Biological Experiments}}},
  author = {Kaltenbach, Hans-Michael},
  date = {2021},
  series = {Statistics for {{Biology}} and {{Health}}},
  publisher = {Springer International Publishing},
  location = {Cham},
  doi = {10.1007/978-3-030-69641-2},
  url = {https://link.springer.com/10.1007/978-3-030-69641-2},
  urldate = {2023-07-18},
  isbn = {978-3-030-69640-5 978-3-030-69641-2},
  langid = {english},
  keywords = {Book,Stat},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\K\Kaltenbach_2021_Statistical Design and Analysis of Biological Experiments.pdf}
}

@article{bailey2021HasseDiagramsVisual,
  title = {Hasse Diagrams as a Visual Aid for Linear Models and Analysis of Variance},
  author = {Bailey, R. A.},
  date = {2021-11-02},
  journaltitle = {Communications in Statistics - Theory and Methods},
  shortjournal = {Communications in Statistics - Theory and Methods},
  volume = {50},
  number = {21},
  pages = {5034--5067},
  issn = {0361-0926, 1532-415X},
  doi = {10.1080/03610926.2019.1676443},
  url = {https://www.tandfonline.com/doi/full/10.1080/03610926.2019.1676443},
  urldate = {2023-09-21},
  abstract = {The expectation part of a linear model is often presented as a single equation with unknown parameters, and the reader is supposed to know that this is shorthand for a whole family of expectation models (for example, is there interaction or not?). It is helpful to list the whole family of models separately and then represent them on a Hasse diagram. This shows which models are sub-models of others, which helps the user to respect marginality when choosing the most parsimonious model to explain the data. Each row in an analysis-ofvariance table corresponds to an edge in the Hasse diagram. In the scaled version of the Hasse diagram, the length of each edge is proportional to the appropriate mean square. This gives a visual display of the analysis of variance (ANOVA). For some people, this is easier to interpret than the standard analysis-of-variance table. Moreover, the scaled Hasse diagram makes clear the difficulties in model choice that can occur under non-orthogonality. The ideas are illustrated using some familiar families of models defined by crossed and nested factors, possibly including polynomial terms for quantitative factors, as well as some more recently introduced families of models for experiments in biodiversity.},
  langid = {english},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\B\Bailey_2021_Hasse diagrams as a visual aid for linear models and analysis of variance.pdf}
}

@book{pearl2020BookWhyNew,
  title = {The Book of Why: The New Science of Cause and Effect},
  shorttitle = {The Book of Why},
  author = {Pearl, Judea and Mackenzie, Dana},
  date = {2020},
  edition = {First trade paperback edition},
  publisher = {Basic Books},
  location = {New York},
  isbn = {978-0-465-09760-9 978-1-5416-9896-3},
  langid = {english},
  pagetotal = {418},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\P\Pearl_Mackenzie_2020_The book of why.pdf}
}

@article{bopp2023IdentifyingPatientsHigh,
  title = {Identifying Patients at High Risk for Multidrug-Resistant Organisms after Hospitalization Abroad},
  author = {Bopp, Tamara C and Marchesi, Martina and Zihlmann, Reto and Sax, Hugo and Wolfensberger, Aline},
  date = {2023-08},
  journaltitle = {Infection Control \& Hospital Epidemiology},
  shortjournal = {Infect. Control Hosp. Epidemiol.},
  volume = {44},
  number = {8},
  pages = {1281--1288},
  issn = {0899-823X, 1559-6834},
  doi = {10.1017/ice.2022.256},
  url = {https://www.cambridge.org/core/product/identifier/S0899823X22002562/type/journal_article},
  urldate = {2023-09-26},
  abstract = {Objectives: We quantified the percentage of multidrug-resistant organism (MDRO) carriers among repatriated patients. We identified factors associated with MDRO carriage, and we evaluated the yield of MDRO detection per screened body site. Design: Retrospective cohort study. Setting: A tertiary-care center in Switzerland. Patients: Adult patients after a stay in a healthcare institution abroad. Methods: Patients were screened for MDRO carriage. Standard sites, including nose and throat, groins, and (since mid-2018) rectum, and riskbased sites (wounds, urine, tracheal secretion) were sampled. MDROs were defined as methicillin-resistant Staphylococcus aureus (MRSA), vancomycin-resistant Enterococcus (VRE), extended-spectrum β-lactamase (ESBL)– and carbapenemase-producing Enterobacterales (CPE), multidrug-resistant (MDR) Enterobacterales, and MDR nonfermenting gram-negative rods. Risk factors for MDRO carriage were assessed using multivariate logistic regression. Results: Between May 2017 and April 2019, 438 patients were screened and 107 (24.4\%) tested positive for an MDRO, predominantly ESBLproducing and MDR Enterobacterales. Risk factors for MDRO colonization were the length of stay in hospital abroad, antibiotic treatment with ‘Watch’ and ‘Reserve’ antibiotics, and region of hospitalization abroad. Rectal swabs had the highest yield for detecting patients with MDR intestinal bacteria, but nose/throat and groins, or wound samples were more sensitive for MRSA or nonfermenting gram-negative organisms, respectively. Conclusions: We identified risk factors for MDRO carriage and body sites with the highest yield for a specific MDRO, which might help to target screening and isolation and reduce screening costs.},
  langid = {english},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\B\Bopp et al_2023_Identifying patients at high risk for multidrug-resistant organisms after.pdf}
}

@article{hernanCausalInferenceWhat,
  title = {Causal {{Inference}}: {{What If}}},
  author = {Hernan, Miguel A and Robins, James M},
  langid = {english},
  keywords = {Book,Stat},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\H\Hernan_Robins_Causal Inference.pdf}
}

@book{peters2017ElementsCausalInference,
  title = {Elements of Causal Inference: Foundations and Learning Algorithms},
  shorttitle = {Elements of Causal Inference},
  author = {Peters, Jonas and Janzing, Dominik and Schölkopf, Bernhard},
  date = {2017},
  series = {Adaptive Computation and Machine Learning},
  publisher = {The MIT press},
  location = {Cambridge, Mass},
  abstract = {"The mathematization of causality is a relatively recent development, and has become increasingly important in data science and machine learning. This book offers a self-contained and concise introduction to causal models and how to learn them from data"--Back of book},
  isbn = {978-0-262-03731-0},
  langid = {english},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\P\Peters et al_2017_Elements of causal inference.pdf}
}

@book{littell2013SASMixedModels,
  title = {{{SAS}} for Mixed Models},
  editor = {Littell, Ramon C.},
  date = {2013},
  edition = {2. ed., 7. print},
  publisher = {SAS Institute},
  location = {Cary, NC},
  isbn = {978-1-59047-500-3 978-1-59994-078-6},
  langid = {english},
  pagetotal = {813},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\L\Littell_2013_SAS for mixed models.pdf}
}

@article{wang2020SampleSizeEstimation,
  title = {Sample {{Size Estimation}} in {{Clinical Research}}},
  author = {Wang, Xiaofeng and Ji, Xinge},
  date = {2020-07},
  journaltitle = {Chest},
  shortjournal = {Chest},
  volume = {158},
  number = {1},
  pages = {S12-S20},
  issn = {00123692},
  doi = {10.1016/j.chest.2020.03.010},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S001236922030458X},
  urldate = {2023-10-09},
  langid = {english},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\W\Wang_Ji_2020_Sample Size Estimation in Clinical Research.pdf}
}

@article{hoenig2001AbusePowerPervasive,
  title = {The {{Abuse}} of {{Power}}: {{The Pervasive Fallacy}} of {{Power Calculations}} for {{Data Analysis}}},
  shorttitle = {The {{Abuse}} of {{Power}}},
  author = {Hoenig, John M and Heisey, Dennis M},
  date = {2001-02},
  journaltitle = {The American Statistician},
  shortjournal = {The American Statistician},
  volume = {55},
  number = {1},
  pages = {19--24},
  issn = {0003-1305, 1537-2731},
  doi = {10.1198/000313001300339897},
  url = {http://www.tandfonline.com/doi/abs/10.1198/000313001300339897},
  urldate = {2023-10-11},
  langid = {english},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\H\Hoenig_Heisey_2001_The Abuse of Power.pdf}
}

@misc{buchner2023PowerManual,
  title = {G*{{Power}} 3.1 Manual},
  author = {Buchner, Axel},
  date = {2023-06-01},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\B\Buchner_2023_GPower 3.pdf}
}

@thesis{zihlmann2016HowDifferencesManagement,
  title = {How Do Differences in Management Reflect on the Carbon Fluxes of a {{Swiss}} Grassland?},
  author = {Zihlmann, Reto},
  date = {2016-07-08},
  institution = {ETH Zürich},
  location = {Zürich},
  abstract = {In times of climate change, a fundamental understanding of carbon dynamics in plant and soil is of great importance. This study examined the short and long-term effects of management events cut, grazing and organic fertilizer application on the carbon dynamics of a high altitude Swiss grassland between 2006-2013. The CO2 flux was measured with the Eddy covariance method and assigned to a particular parcel according to the prevalent wind direction. The parcels differed in management intensity and in soil properties. Generally, cut and grazing led to a significant increase of CO2 flux whereas the application of organic fertilizer results in a decrease. These findings only apply to a short time period after the events. They slightly affect the temporal course of the CO2 flux but did not lead to major distinction. The decomposition of peat in a formerly heavily waterlogged parcel turned out to be much more influential on the CO2 flux than the management differences, even 35 years after the beginning of drainage.},
  langid = {english},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\Z\Zihlmann_2016_How do differences in management reflect on the carbon fluxes of a Swiss.pdf}
}

@thesis{zihlmann2018GeneticDeterminantsLeaf,
  title = {Genetic Determinants of Leaf Growth Response to Environment in Wheat},
  author = {Zihlmann, Reto},
  date = {2018-09-01},
  institution = {ETH Zürich},
  location = {Zürich},
  abstract = {An increase in crop water stress is expected in many regions over coming decades. Therefore, there is a need for drought tolerant and high yielding wheat varieties to ensure global food security. Breeding on drought tolerance has proven to be difficult as there is no fast, automated and reproducible phenotyping method linked to yield under water stress. In this study, we present a method measuring leaf elongation rate (LER) on a high temporal resolution. 320 wheat varieties with three replicates were grown for one week in a greenhouse and were exposed to increasing water stress. LER was measured along with temperature, air humidity, light and gravimetric water content (GWC) of the substrate. Genotype specific response curves to environmental variables were used to model LER. The resulting model was able to predict LER of an unseen data set (R 2 = 0.40). A genome wide association study (GWAS) resulted in some interesting candidate genes for genotype specific drought response which might be further examined. The entire phenotyping process was cheap and could easily be adapted by breeders. It led to a rough characterization of drought tolerance within three weeks. This opens the way for selection on drought tolerance at an early breeding stage.},
  langid = {english},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\Z\Zihlmann_2018_Genetic determinants of leaf growth response to environment in wheat.pdf}
}

@thesis{zihlmann2020GeneralizedLinearMixed,
  title = {Generalized {{Linear Mixed Eﬀects Models}} in {{Genetic Evaluations}}},
  author = {Zihlmann, Reto},
  date = {2020-08-31},
  institution = {ETH Zürich},
  location = {Zürich},
  abstract = {Health and reproductive traits are increasingly important in cattle breeding programms all around the world. In contrast to productivity traits, health and reproductive traits are often measured on a nominal or ordinal scale which makes classical breeding value estimation via linear mixed effects models (LMMs) inappropriate. Despite extensive litherature, application of generalized linear mixed effects models (GLMMs) and threshold models in practical breeding value estimation remains challenging due to limited availability of software implementation for this specific purpose. In this study we present available software packages, show their weaknesses and implement improvements. The implementations were tested on simulated data sets and compared with respect to computation time and accuracy of the estimated breeding values. The best implementations were applied to realworld data sets of some major Swiss cattle populations. Traits of interest were multiple birth, early-life calf survival and carcass confirmation scores. GLMMs and threshold models clearly improved the prediction of breeding values compared to LMMs when applied to simulated binary and ordinal traits. Bayesian implementations performed relatively slow for small data sets but returned trustworthy standard errors of the estimated breeding value by accounting for the uncertainty of variance component estimation. The improvements also came at a higher computational cost, however, the cost was largely reduced by assuming known variance components. A similar strategy was successfully applied to the much larger real world data sets by separately estimating variance components and animal breeding values. This study shows that GLMMs and threshold models can and should be applied for non-normal traits in order to improve the properties of estimated breeding value and obtain unbiased heritability estimates which allow for well-informed constructions of selection indices.},
  langid = {english},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\Z\Zihlmann_2020_Generalized Linear Mixed Eﬀects Models in Genetic Evaluations.pdf}
}

@article{arns-glaser2023EstimatingHabitualIodine,
  title = {Estimating Habitual Iodine Intake and Prevalence of Inadequacy from Spot Urine in Cross-Sectional Studies: A Modeling Analysis to Determine the Required Sample Size},
  shorttitle = {Estimating Habitual Iodine Intake and Prevalence of Inadequacy from Spot Urine in Cross-Sectional Studies},
  author = {Arns-Glaser, Leonie and Zihlmann, Reto and Gessler, Sara and Verkaik-Kloosterman, Janneke and Zandberg, Lizelle and Assey, Vincent D. and Rigutto-Farebrother, Jessica and Braegger, Christian P. and Zimmermann, Michael B. and Andersson, Maria},
  date = {2023-06},
  journaltitle = {The American Journal of Clinical Nutrition},
  shortjournal = {The American Journal of Clinical Nutrition},
  volume = {117},
  number = {6},
  pages = {1270--1277},
  issn = {00029165},
  doi = {10.1016/j.ajcnut.2023.03.012},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0002916523462685},
  urldate = {2023-12-03},
  langid = {english},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\A\Arns-Glaser_Estimating habitual iodine intake and prevalence of inadequacy from spot urine.pdf}
}

@article{niu2018PredictionEntericMethane,
  title = {Prediction of Enteric Methane Production, Yield, and Intensity in Dairy Cattle Using an Intercontinental Database},
  author = {Niu, Mutian and Kebreab, Ermias and Hristov, Alexander N. and Oh, Joonpyo and Arndt, Claudia and Bannink, André and Bayat, Ali R. and Brito, André F. and Boland, Tommy and Casper, David and Crompton, Les A. and Dijkstra, Jan and Eugène, Maguy A. and Garnsworthy, Phil C. and Haque, Md Najmul and Hellwing, Anne L. F. and Huhtanen, Pekka and Kreuzer, Michael and Kuhla, Bjoern and Lund, Peter and Madsen, Jørgen and Martin, Cécile and McClelland, Shelby C. and McGee, Mark and Moate, Peter J. and Muetzel, Stefan and Muñoz, Camila and O'Kiely, Padraig and Peiren, Nico and Reynolds, Christopher K. and Schwarm, Angela and Shingfield, Kevin J. and Storlien, Tonje M. and Weisbjerg, Martin R. and Yáñez-Ruiz, David R. and Yu, Zhongtang},
  date = {2018},
  journaltitle = {Global Change Biology},
  volume = {24},
  number = {8},
  pages = {3368--3389},
  issn = {1365-2486},
  doi = {10.1111/gcb.14094},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/gcb.14094},
  urldate = {2024-01-17},
  abstract = {Enteric methane (CH4) production from cattle contributes to global greenhouse gas emissions. Measurement of enteric CH4 is complex, expensive, and impractical at large scales; therefore, models are commonly used to predict CH4 production. However, building robust prediction models requires extensive data from animals under different management systems worldwide. The objectives of this study were to (1) collate a global database of enteric CH4 production from individual lactating dairy cattle; (2) determine the availability of key variables for predicting enteric CH4 production (g/day per cow), yield [g/kg dry matter intake (DMI)], and intensity (g/kg energy corrected milk) and their respective relationships; (3) develop intercontinental and regional models and cross-validate their performance; and (4) assess the trade-off between availability of on-farm inputs and CH4 prediction accuracy. The intercontinental database covered Europe (EU), the United States (US), and Australia (AU). A sequential approach was taken by incrementally adding key variables to develop models with increasing complexity. Methane emissions were predicted by fitting linear mixed models. Within model categories, an intercontinental model with the most available independent variables performed best with root mean square prediction error (RMSPE) as a percentage of mean observed value of 16.6\%, 14.7\%, and 19.8\% for intercontinental, EU, and United States regions, respectively. Less complex models requiring only DMI had predictive ability comparable to complex models. Enteric CH4 production, yield, and intensity prediction models developed on an intercontinental basis had similar performance across regions, however, intercepts and slopes were different with implications for prediction. Revised CH4 emission conversion factors for specific regions are required to improve CH4 production estimates in national inventories. In conclusion, information on DMI is required for good prediction, and other factors such as dietary neutral detergent fiber (NDF) concentration, improve the prediction. For enteric CH4 yield and intensity prediction, information on milk yield and composition is required for better estimation.},
  langid = {english},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\N\Niu et al_2018_Prediction of enteric methane production, yield, and intensity in dairy cattle.pdf}
}

@article{niu2021BasicModelPredict,
  title = {A {{Basic Model}} to {{Predict Enteric Methane Emission}} from {{Dairy Cows}} and {{Its Application}} to {{Update Operational Models}} for the {{National Inventory}} in {{Norway}}},
  author = {Niu, Puchun and Schwarm, Angela and Bonesmo, Helge and Kidane, Alemayehu and Aspeholen Åby, Bente and Storlien, Tonje Marie and Kreuzer, Michael and Alvarez, Clementina and Sommerseth, Jon Kristian and Prestløkken, Egil},
  date = {2021-07},
  journaltitle = {Animals},
  volume = {11},
  number = {7},
  pages = {1891},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2076-2615},
  doi = {10.3390/ani11071891},
  url = {https://www.mdpi.com/2076-2615/11/7/1891},
  urldate = {2024-01-17},
  abstract = {The aim of this study was to develop a basic model to predict enteric methane emission from dairy cows and to update operational calculations for the national inventory in Norway. Development of basic models utilized information that is available only from feeding experiments. Basic models were developed using a database with 63 treatment means from 19 studies and were evaluated against an external database (n = 36, from 10 studies) along with other extant models. In total, the basic model database included 99 treatment means from 29 studies with records for enteric CH4 production (MJ/day), dry matter intake (DMI) and dietary nutrient composition. When evaluated by low root mean square prediction errors and high concordance correlation coefficients, the developed basic models that included DMI, dietary concentrations of fatty acids and neutral detergent fiber performed slightly better in predicting CH4 emissions than extant models. In order to propose country-specific values for the CH4 conversion factor Ym (\% of gross energy intake partitioned into CH4) and thus to be able to carry out the national inventory for Norway, the existing operational model was updated for the prediction of Ym over a wide range of feeding situations. A simulated operational database containing CH4 production (predicted by the basic model), feed intake and composition, Ym and gross energy intake (GEI), in addition to the predictor variables energy corrected milk yield and dietary concentrate share were used to develop an operational model. Input values of Ym were updated based on the results from the basic models. The predicted Ym ranged from 6.22 to 6.72\%. In conclusion, the prediction accuracy of CH4 production from dairy cows was improved with the help of newly published data, which enabled an update of the operational model for calculating the national inventory of CH4 in Norway.},
  issue = {7},
  langid = {english},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\N\Niu et al_2021_A Basic Model to Predict Enteric Methane Emission from Dairy Cows and Its.pdf}
}

@article{zhang2023MethanePredictionEquations,
  title = {Methane Prediction Equations Including Genera of Rumen Bacteria as Predictor Variables Improve Prediction Accuracy},
  author = {Zhang, Boyang and Lin, Shili and Moraes, Luis and Firkins, Jeffrey and Hristov, Alexander N. and Kebreab, Ermias and Janssen, Peter H. and Bannink, André and Bayat, Alireza R. and Crompton, Les A. and Dijkstra, Jan and Eugène, Maguy A. and Kreuzer, Michael and McGee, Mark and Reynolds, Christopher K. and Schwarm, Angela and Yáñez-Ruiz, David R. and Yu, Zhongtang},
  date = {2023-12-02},
  journaltitle = {Scientific Reports},
  shortjournal = {Sci Rep},
  volume = {13},
  number = {1},
  pages = {21305},
  publisher = {Nature Publishing Group},
  issn = {2045-2322},
  doi = {10.1038/s41598-023-48449-y},
  url = {https://www.nature.com/articles/s41598-023-48449-y},
  urldate = {2024-01-17},
  abstract = {Methane (CH4) emissions from ruminants are of a significant environmental concern, necessitating accurate prediction for emission inventories. Existing models rely solely on dietary and host animal-related data, ignoring the predicting power of rumen microbiota, the source of CH4. To address this limitation, we developed novel CH4 prediction models incorporating rumen microbes as predictors, alongside animal- and feed-related predictors using four statistical/machine learning (ML) methods. These include random forest combined with boosting (RF-B), least absolute shrinkage and selection operator (LASSO), generalized linear mixed model with LASSO (glmmLasso), and smoothly clipped absolute deviation (SCAD) implemented on linear mixed models. With a sheep dataset (218 observations) of both animal data and rumen microbiota data (relative sequence abundance of 330 genera of rumen bacteria, archaea, protozoa, and fungi), we developed linear mixed models to predict CH4 production (g CH4/animal·d, ANIM-B models) and CH4 yield (g CH4/kg of dry matter intake, DMI-B models). We also developed models solely based on animal-related data. Prediction performance was evaluated 200 times with random data splits, while fitting performance was assessed without data splitting. The inclusion of microbial predictors improved the models, as indicated by decreased root mean square prediction error (RMSPE) and mean absolute error (MAE), and increased Lin’s concordance correlation coefficient (CCC). Both glmmLasso and SCAD reduced the Akaike information criterion (AIC) and Bayesian information criterion (BIC) for both the ANIM-B and the DMI-B models, while the other two ML methods had mixed outcomes. By balancing prediction performance and fitting performance, we obtained one ANIM-B model (containing 10 genera of bacteria and 3 animal data) fitted using glmmLasso and one DMI-B model (5 genera of bacteria and 1 animal datum) fitted using SCAD. This study highlights the importance of incorporating rumen microbiota data in CH4 prediction models to enhance accuracy and robustness. Additionally, ML methods facilitate the selection of microbial predictors from high-dimensional metataxonomic data of the rumen microbiota without overfitting. Moreover, the identified microbial predictors can serve as biomarkers of CH4 emissions from sheep, providing valuable insights for future research and mitigation strategies.},
  issue = {1},
  langid = {english},
  keywords = {Microbiom},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\Z\Zhang et al_2023_Methane prediction equations including genera of rumen bacteria as predictor.pdf}
}

@article{kittelmann2014TwoDifferentBacterial,
  title = {Two {{Different Bacterial Community Types Are Linked}} with the {{Low-Methane Emission Trait}} in {{Sheep}}},
  author = {Kittelmann, Sandra and Pinares-Patiño, Cesar S. and Seedorf, Henning and Kirk, Michelle R. and Ganesh, Siva and McEwan, John C. and Janssen, Peter H.},
  date = {2014-07-31},
  journaltitle = {PLOS ONE},
  shortjournal = {PLOS ONE},
  volume = {9},
  number = {7},
  pages = {e103171},
  publisher = {Public Library of Science},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0103171},
  url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0103171},
  urldate = {2024-01-17},
  abstract = {The potent greenhouse gas methane (CH4) is produced in the rumens of ruminant animals from hydrogen produced during microbial degradation of ingested feed. The natural animal-to-animal variation in the amount of CH4 emitted and the heritability of this trait offer a means for reducing CH4 emissions by selecting low-CH4 emitting animals for breeding. We demonstrate that differences in rumen microbial community structure are linked to high and low CH4 emissions in sheep. Bacterial community structures in 236 rumen samples from 118 high- and low-CH4 emitting sheep formed gradual transitions between three ruminotypes. Two of these (Q and S) were linked to significantly lower CH4 yields (14.4 and 13.6 g CH4/kg dry matter intake [DMI], respectively) than the third type (H; 15.9 g CH4/kg DMI; p{$<$}0.001). Low-CH4 ruminotype Q was associated with a significantly lower ruminal acetate to propionate ratio (3.7±0.4) than S (4.4±0.7; p{$<$}0.001) and H (4.3±0.5; p{$<$}0.001), and harbored high relative abundances of the propionate-producing Quinella ovalis. Low-CH4 ruminotype S was characterized by lactate- and succinate-producing Fibrobacter spp., Kandleria vitulina, Olsenella spp., Prevotella bryantii, and Sharpea azabuensis. High-CH4 ruminotype H had higher relative abundances of species belonging to Ruminococcus, other Ruminococcaceae, Lachnospiraceae, Catabacteriaceae, Coprococcus, other Clostridiales, Prevotella, other Bacteroidales, and Alphaproteobacteria, many of which are known to form significant amounts of hydrogen. We hypothesize that lower CH4 yields are the result of bacterial communities that ferment ingested feed to relatively less hydrogen, which results in less CH4 being formed.},
  langid = {english},
  keywords = {Microbiom},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\K\Kittelmann et al_2014_Two Different Bacterial Community Types Are Linked with the Low-Methane.pdf}
}

@article{donadia2023FactorsAffectingEnteric,
  title = {Factors {{Affecting Enteric Emission Methane}} and {{Predictive Models}} for {{Dairy Cows}}},
  author = {Donadia, Andrea Beltrani and Torres, Rodrigo Nazaré Santos and family=Silva, given=Henrique Melo, prefix=da, useprefix=true and Soares, Suziane Rodrigues and Hoshide, Aaron Kinyu and family=Oliveira, given=André Soares, prefix=de, useprefix=true},
  date = {2023-06-02},
  journaltitle = {Animals : an Open Access Journal from MDPI},
  shortjournal = {Animals (Basel)},
  volume = {13},
  number = {11},
  eprint = {37889787},
  eprinttype = {pmid},
  pages = {1857},
  issn = {2076-2615},
  doi = {10.3390/ani13111857},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10252078/},
  urldate = {2024-01-17},
  abstract = {Simple Summary Meeting the growing animal food demand while reducing greenhouse gas emissions (GGEs) remains one of the challenges for global livestock industries. Enteric methane emission (EME) is the main GGE source in dairy cattle systems. Therefore, evaluating the drivers of EME intensity (per animal product) and developing more accurate predictive models of EME may contribute to dairy cattle sustainability. In this study, we built a large and intercontinental experimental dataset to: (1) explain the effect of EME yield (g methane/kg diet intake) and feed conversion (kg diet intake/kg milk yield) on EME intensity (g methane/kg milk yield); (2) develop models from predicting EME (g/cow/day); and (3) compare the proposed models with 43 external models. Increasing the milk yield reduced EME intensity, and this effect was more due to the enhancement in feed conversion than EME yield. Our models predicted methane emissions better than most external models, with the exception of only two other models which had similar adequacy. Our findings confirm that the improvement in feed conversion should be prioritized for reducing methane emissions in dairy cattle systems. Abstract Enteric methane emission is the main source of greenhouse gas contribution from dairy cattle. Therefore, it is essential to evaluate drivers and develop more accurate predictive models for such emissions. In this study, we built a large and intercontinental experimental dataset to: (1) explain the effect of enteric methane emission yield (g methane/kg diet intake) and feed conversion (kg diet intake/kg milk yield) on enteric methane emission intensity (g methane/kg milk yield); (2) develop six models for predicting enteric methane emissions (g/cow/day) using animal, diet, and dry matter intake as inputs; and to (3) compare these 6 models with 43 models from the literature. Feed conversion contributed more to enteric methane emission (EME) intensity than EME yield. Increasing the milk yield reduced EME intensity, due more to feed conversion enhancement rather than EME yield. Our models predicted methane emissions better than most external models, with the exception of only two other models which had similar adequacy. Improved productivity of dairy cows reduces emission intensity by enhancing feed conversion. Improvement in feed conversion should be prioritized for reducing methane emissions in dairy cattle systems.},
  pmcid = {PMC10252078},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\D\Donadia et al_2023_Factors Affecting Enteric Emission Methane and Predictive Models for Dairy Cows.pdf}
}

@article{ross2013MetagenomicPredictionsMicrobiome,
  title = {Metagenomic {{Predictions}}: {{From Microbiome}} to {{Complex Health}} and {{Environmental Phenotypes}} in {{Humans}} and {{Cattle}}},
  shorttitle = {Metagenomic {{Predictions}}},
  author = {Ross, Elizabeth M. and Moate, Peter J. and Marett, Leah C. and Cocks, Ben G. and Hayes, Ben J.},
  date = {2013-04-09},
  journaltitle = {PLOS ONE},
  shortjournal = {PLOS ONE},
  volume = {8},
  number = {9},
  pages = {e73056},
  publisher = {Public Library of Science},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0073056},
  url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0073056},
  urldate = {2024-01-23},
  abstract = {Mammals have a large cohort of endo- and ecto- symbiotic microorganisms (the microbiome) that potentially influence host phenotypes. There have been numerous exploratory studies of these symbiotic organisms in humans and other animals, often with the aim of relating the microbiome to a complex phenotype such as body mass index (BMI) or disease state. Here, we describe an efficient methodology for predicting complex traits from quantitative microbiome profiles. The method was demonstrated by predicting inflammatory bowel disease (IBD) status and BMI from human microbiome data, and enteric greenhouse gas production from dairy cattle rumen microbiome profiles. The method uses unassembled massively parallel sequencing (MPS) data to form metagenomic relationship matrices (analogous to genomic relationship matrices used in genomic predictions) to predict IBD, BMI and methane production phenotypes with useful accuracies (r = 0.423, 0.422 and 0.466 respectively). Our results show that microbiome profiles derived from MPS can be used to predict complex phenotypes of the host. Although the number of biological replicates used here limits the accuracy that can be achieved, preliminary results suggest this approach may surpass current prediction accuracies that are based on the host genome. This is especially likely for traits that are largely influenced by the gut microbiota, for example digestive tract disorders or metabolic functions such as enteric methane production in cattle.},
  langid = {english},
  keywords = {Microbiom},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\R\Ross et al_2013_Metagenomic Predictions.pdf}
}

@article{peng2023UnveilingMicrobialBiomarkers,
  title = {Unveiling Microbial Biomarkers of Ruminant Methane Emission through Machine Learning},
  author = {Peng, Chengyao and May, Ali and Abeel, Thomas},
  date = {2023-12-08},
  journaltitle = {Frontiers in Microbiology},
  shortjournal = {Front. Microbiol.},
  volume = {14},
  pages = {1308363},
  issn = {1664-302X},
  doi = {10.3389/fmicb.2023.1308363},
  url = {https://www.frontiersin.org/articles/10.3389/fmicb.2023.1308363/full},
  urldate = {2024-01-23},
  abstract = {Background: Enteric methane from cow burps, which results from microbial fermentation of high-fiber feed in the rumen, is a significant contributor to greenhouse gas emissions. A promising strategy to address this problem is microbiome-based precision feed, which involves identifying key microorganisms for methane production. While machine learning algorithms have shown success in associating human gut microbiome with various human diseases, there have been limited e orts to employ these algorithms to establish microbial biomarkers for methane emissions in ruminants. Methods: In this study, we aim to identify potential methane biomarkers for methane emission from ruminants by employing regression algorithms commonly used in human microbiome studies, coupled with di erent feature selection methods. To achieve this, we analyzed the microbiome compositions and identified possible confounding metadata variables in two large public datasets of Holstein cows. Using both the microbiome features and identified metadata variables, we trained di erent regressors to predict methane emission. With the optimized models, permutation tests were used to determine feature importance to find informative microbial features. Results: Among the regression algorithms tested, random forest regression outperformed others and allowed the identification of several crucial microbial taxa for methane emission as members of the native rumen microbiome, including the genera Piromyces, Succinivibrionaceae UCG- , and Acetobacter. Additionally, our results revealed that certain herd locations and feed composition markers, such as the lipid intake and neutral-detergent fiber intake, are also predictive features for methane emissions. Conclusion: We demonstrated that machine learning, particularly regression algorithms, can e ectively predict cow methane emissions and identify relevant rumen microorganisms. Our findings o er valuable insights for the development of microbiome-based precision feed strategies aiming at reducing methane emissions.},
  langid = {english},
  keywords = {Microbiom},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\P\Peng et al_2023_Unveiling microbial biomarkers of ruminant methane emission through machine.pdf}
}

@article{vanlingen2017DiurnalDynamicsGaseous,
  title = {Diurnal {{Dynamics}} of {{Gaseous}} and {{Dissolved Metabolites}} and {{Microbiota Composition}} in the {{Bovine Rumen}}},
  author = {family=Lingen, given=Henk J., prefix=van, useprefix=true and Edwards, Joan E. and Vaidya, Jueeli D. and family=Gastelen, given=Sanne, prefix=van, useprefix=true and Saccenti, Edoardo and family=Bogert, given=Bartholomeus, prefix=van den, useprefix=true and Bannink, André and Smidt, Hauke and Plugge, Caroline M. and Dijkstra, Jan},
  date = {2017},
  journaltitle = {Frontiers in Microbiology},
  volume = {8},
  issn = {1664-302X},
  url = {https://www.frontiersin.org/articles/10.3389/fmicb.2017.00425},
  urldate = {2024-01-23},
  abstract = {Diurnal patterns of ruminal fermentation metabolites and microbial communities are not commonly assessed when investigating variation in ruminal CH4 production. The aims of this study were to monitor diurnal patterns of: (i) gaseous and dissolved metabolite concentrations in the bovine rumen, (ii) H2 and CH4 emitted, and (iii) the rumen microbiota. Furthermore, the effect of dietary inclusion of linseed oil on these patterns was assessed. Four rumen cannulated multiparous cows were used in a cross-over design with two 17 days periods and two dietary treatments: a control diet and a linseed oil supplemented diet [40\% maize silage, 30\% grass silage, 30\% concentrate on dry matter (DM) basis for both diets; fat contents of 33 vs. 56 g/kg of DM]. On day 11, rumen contents were sampled for 10 h after morning feeding to profile gaseous and dissolved metabolite concentrations and microbiota composition. H2 and CH4 emission (mass per unit of time) was measured in respiration chambers from day 13 to 17. A 100-fold increase in ruminal H2 partial pressure (contribution to the total pressure of rumen headspace gases) was observed at 0.5 h after feeding. This peak was followed by a decline to basal level. Qualitatively similar patterns after feeding were also observed for H2 and CH4 emission, ethanol and lactate concentrations, and propionate molar proportion, although the opposite pattern was seen for acetate molar proportion. Associated with these patterns, a temporal biphasic change in the microbial composition was observed as based on 16S ribosomal RNA with certain taxa specifically associated with each phase. Bacterial concentrations (log10 16S ribosomal RNA gene copies based) were affected by time, and were increased by linseed oil supplementation. Archaeal concentrations (log10 16S ribosomal RNA gene copies based) tended to be affected by time and were not affected by diet, despite linseed oil supplementation decreasing CH4 emission, tending to decrease the partial pressure of CH4, and tending to increase propionate molar proportion. Linseed oil supplementation affected microbiota composition, and was most associated with an uncultivated Bacteroidales taxon. In summary, our findings support the importance of diurnal dynamics for the understanding of VFA, H2, and CH4 production.},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\V\van Lingen et al_2017_Diurnal Dynamics of Gaseous and Dissolved Metabolites and Microbiota.pdf}
}

@article{seymour2005RelationshipsRumenVolatile,
  title = {Relationships between Rumen Volatile Fatty Acid Concentrations and Milk Production in Dairy Cows: A Literature Study},
  shorttitle = {Relationships between Rumen Volatile Fatty Acid Concentrations and Milk Production in Dairy Cows},
  author = {Seymour, W.M. and Campbell, D.R. and Johnson, Z.B.},
  date = {2005-03},
  journaltitle = {Animal Feed Science and Technology},
  shortjournal = {Animal Feed Science and Technology},
  volume = {119},
  number = {1-2},
  pages = {155--169},
  issn = {03778401},
  doi = {10.1016/j.anifeedsci.2004.10.001},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0377840104002299},
  urldate = {2024-05-08},
  abstract = {Data from 20 research studies with 92 treatment means were summarized from the journals of dairy science and animal science 2000–2002. All studies were conducted with Holstein cows in Latin square or simple reversal design and included serial sampling of rumen fluid via cannula. Treatments included the effects of feeding various carbohydrate sources, corn milling byproducts, particle size of forage or grain, level of non-structural carbohydrates and the source and digestibility of forages. Studies included rations based on both stored forages and pasture. Simple statistics, correlation, linear regression and mixed model analysis assessing the random effect of study were used to describe the relationships between rumen and production parameters.},
  langid = {english},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\S\Seymour et al_2005_Relationships between rumen volatile fatty acid concentrations and milk.pdf}
}

@article{arndt2022FullAdoptionMost,
  title = {Full Adoption of the Most Effective Strategies to Mitigate Methane Emissions by Ruminants Can Help Meet the 1.5\,°{{C}} Target by 2030 but Not 2050},
  author = {Arndt, Claudia and Hristov, Alexander N. and Price, William J. and McClelland, Shelby C. and Pelaez, Amalia M. and Cueva, Sergio F. and Oh, Joonpyo and Dijkstra, Jan and Bannink, André and Bayat, Ali R. and Crompton, Les A. and Eugène, Maguy A. and Enahoro, Dolapo and Kebreab, Ermias and Kreuzer, Michael and McGee, Mark and Martin, Cécile and Newbold, Charles J. and Reynolds, Christopher K. and Schwarm, Angela and Shingfield, Kevin J. and Veneman, Jolien B. and Yáñez-Ruiz, David R. and Yu, Zhongtang},
  date = {2022-05-17},
  journaltitle = {Proceedings of the National Academy of Sciences},
  volume = {119},
  number = {20},
  pages = {e2111294119},
  publisher = {Proceedings of the National Academy of Sciences},
  doi = {10.1073/pnas.2111294119},
  url = {https://www.pnas.org/doi/full/10.1073/pnas.2111294119},
  urldate = {2024-05-14},
  abstract = {To meet the 1.5\,°C target, methane (CH4) from ruminants must be reduced by 11 to 30\% by 2030 and 24 to 47\% by 2050 compared to 2010 levels. A meta-analysis identified strategies to decrease product-based (PB; CH4 per unit meat or milk) and absolute (ABS) enteric CH4 emissions while maintaining or increasing animal productivity (AP; weight gain or milk yield). Next, the potential of different adoption rates of one PB or one ABS strategy to contribute to the 1.5\,°C target was estimated. The database included findings from 430 peer-reviewed studies, which reported 98 mitigation strategies that can be classified into three categories: animal and feed management, diet formulation, and rumen manipulation. A random-effects meta-analysis weighted by inverse variance was carried out. Three PB strategies—namely, increasing feeding level, decreasing grass maturity, and decreasing dietary forage-to-concentrate ratio—decreased CH4 per unit meat or milk by on average 12\% and increased AP by a median of 17\%. Five ABS strategies—namely CH4 inhibitors, tanniferous forages, electron sinks, oils and fats, and oilseeds—decreased daily methane by on average 21\%. Globally, only 100\% adoption of the most effective PB and ABS strategies can meet the 1.5\,°C target by 2030 but not 2050, because mitigation effects are offset by projected increases in CH4 due to increasing milk and meat demand. Notably, by 2030 and 2050, low- and middle-income countries may not meet their contribution to the 1.5\,°C target for this same reason, whereas high-income countries could meet their contributions due to only a minor projected increase in enteric CH4 emissions.},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\A\Arndt et al_2022_Full adoption of the most effective strategies to mitigate methane emissions by.pdf}
}

@article{harshaw2024BalancingCovariatesRandomized,
  title = {Balancing {{Covariates}} in {{Randomized Experiments}} with the {{Gram}}–{{Schmidt Walk Design}}},
  author = {Harshaw, Christopher and Sävje, Fredrik and Spielman, Daniel A. and Zhang, Peng},
  date = {2024},
  journaltitle = {Journal of the American Statistical Association},
  volume = {0},
  number = {0},
  pages = {1--13},
  publisher = {Taylor \& Francis},
  issn = {0162-1459},
  doi = {10.1080/01621459.2023.2285474},
  url = {https://doi.org/10.1080/01621459.2023.2285474},
  urldate = {2024-06-19},
  abstract = {The design of experiments involves a compromise between covariate balance and robustness. This article provides a formalization of this tradeoff and describes an experimental design that allows experimenters to navigate it. The design is specified by a robustness parameter that bounds the worst-case mean squared error of an estimator of the average treatment effect. Subject to the experimenter’s desired level of robustness, the design aims to simultaneously balance all linear functions of potentially many covariates. Less robustness allows for more balance. We show that the mean squared error of the estimator is bounded in finite samples by the minimum of the loss function of an implicit ridge regression of the potential outcomes on the covariates. Asymptotically, the design perfectly balances all linear functions of a growing number of covariates with a diminishing reduction in robustness, effectively allowing experimenters to escape the compromise between balance and robustness in large samples. Finally, we describe conditions that ensure asymptotic normality and provide a conservative variance estimator, which facilitate the construction of asymptotically valid confidence intervals. Supplementary materials for this article are available online.},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\H\Harshaw et al_2024_Balancing Covariates in Randomized Experiments with the Gram–Schmidt Walk Design.pdf}
}

@article{nordin2022PropertiesRestrictedRandomization,
  title = {Properties of Restricted Randomization with Implications for Experimental Design},
  author = {Nordin, Mattias and Schultzberg, Mårten},
  date = {2022-01-01},
  journaltitle = {Journal of Causal Inference},
  volume = {10},
  number = {1},
  pages = {227--245},
  publisher = {De Gruyter},
  issn = {2193-3685},
  doi = {10.1515/jci-2021-0057},
  url = {https://www.degruyter.com/document/doi/10.1515/jci-2021-0057/html?lang=en},
  urldate = {2024-06-20},
  abstract = {Recently, there has been increasing interest in the use of heavily restricted randomization designs which enforce balance on observed covariates in randomized controlled trials. However, when restrictions are strict, there is a risk that the treatment effect estimator will have a very high mean squared error (MSE). In this article, we formalize this risk and propose a novel combinatoric-based approach to describe and address this issue. First, we validate our new approach by re-proving some known properties of complete randomization and restricted randomization. Second, we propose a novel diagnostic measure for restricted designs that only use the information embedded in the combinatorics of the design. Third, we show that the variance of the MSE of the difference-in-means estimator in a randomized experiment is a linear function of this diagnostic measure. Finally, we identify situations in which restricted designs can lead to an increased risk of getting a high MSE and discuss how our diagnostic measure can be used to detect such designs. Our results have implications for any restricted randomization design and can be used to evaluate the trade-off between enforcing balance on observed covariates and avoiding too restrictive designs.},
  langid = {english},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\N\Nordin_Schultzberg_2022_Properties of restricted randomization with implications for experimental design.pdf}
}

@article{morgan2012RerandomizationImproveCovariate,
  title = {Rerandomization to Improve Covariate Balance in Experiments},
  author = {Morgan, Kari Lock and Rubin, Donald B.},
  date = {2012-04-01},
  journaltitle = {The Annals of Statistics},
  shortjournal = {Ann. Statist.},
  volume = {40},
  number = {2},
  eprint = {1207.5625},
  eprinttype = {arXiv},
  eprintclass = {math, stat},
  issn = {0090-5364},
  doi = {10.1214/12-AOS1008},
  url = {http://arxiv.org/abs/1207.5625},
  urldate = {2024-07-15},
  abstract = {Randomized experiments are the "gold standard" for estimating causal effects, yet often in practice, chance imbalances exist in covariate distributions between treatment groups. If covariate data are available before units are exposed to treatments, these chance imbalances can be mitigated by first checking covariate balance before the physical experiment takes place. Provided a precise definition of imbalance has been specified in advance, unbalanced randomizations can be discarded, followed by a rerandomization, and this process can continue until a randomization yielding balance according to the definition is achieved. By improving covariate balance, rerandomization provides more precise and trustworthy estimates of treatment effects.},
  langid = {english},
  file = {C:\Users\858782\Zotero\storage\PRY6XIGK\Morgan and Rubin - 2012 - Rerandomization to improve covariate balance in ex.pdf}
}

@article{harville1974NearlyOptimalAllocation,
  title = {Nearly {{Optimal Allocation}} of {{Experimental Units Using Observed Covariate Values}}},
  author = {Harville, David A.},
  date = {1974-11},
  journaltitle = {Technometrics},
  shortjournal = {Technometrics},
  volume = {16},
  number = {4},
  pages = {589--599},
  issn = {0040-1706, 1537-2723},
  doi = {10.1080/00401706.1974.10489242},
  url = {http://www.tandfonline.com/doi/abs/10.1080/00401706.1974.10489242},
  urldate = {2024-07-19},
  langid = {english},
  file = {C:\Users\858782\Zotero\storage\S6679LQN\Harville - 1974 - Nearly Optimal Allocation of Experimental Units Us.pdf}
}

@article{efronForcingSequentialExperiment,
  title = {Forcing a Sequential Experiment to Be Balanced},
  author = {Efron, Bradley},
  langid = {english},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\E\Efron_Forcing a sequential experiment to be balanced.pdf}
}

@thesis{maigaardCOMBININGFEEDADDITIVES,
  title = {{{COMBINING FEED ADDITIVES TO MITIGATE METHANE EMISSION AND REDIRECT HYDROGEN IN DAIRY COWS}}},
  author = {Maigaard, Morten},
  langid = {english},
  file = {C:\Users\858782\Zotero\storage\T3WJZL5B\Maigaard - COMBINING FEED ADDITIVES TO MITIGATE METHANE EMISS.pdf}
}

@article{vanlingen2019PredictionEntericMethane,
  title = {Prediction of Enteric Methane Production, Yield and Intensity of Beef Cattle Using an Intercontinental Database},
  author = {family=Lingen, given=Henk J., prefix=van, useprefix=true and Niu, Mutian and Kebreab, Ermias and Valadares Filho, Sebastião C. and Rooke, John A. and Duthie, Carol-Anne and Schwarm, Angela and Kreuzer, Michael and Hynd, Phil I. and Caetano, Mariana and Eugène, Maguy and Martin, Cécile and McGee, Mark and O’Kiely, Padraig and Hünerberg, Martin and McAllister, Tim A. and Berchielli, Telma T. and Messana, Juliana D. and Peiren, Nico and Chaves, Alex V. and Charmley, Ed and Cole, N. Andy and Hales, Kristin E. and Lee, Sang-Suk and Berndt, Alexandre and Reynolds, Christopher K. and Crompton, Les A. and Bayat, Ali-Reza and Yáñez-Ruiz, David R. and Yu, Zhongtang and Bannink, André and Dijkstra, Jan and Casper, David P. and Hristov, Alexander N.},
  date = {2019-11},
  journaltitle = {Agriculture, Ecosystems \& Environment},
  shortjournal = {Agriculture, Ecosystems \& Environment},
  volume = {283},
  pages = {106575},
  issn = {01678809},
  doi = {10.1016/j.agee.2019.106575},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0167880919301914},
  urldate = {2024-08-13},
  langid = {english},
  file = {C:\Users\858782\Zotero\storage\WP3YCTU2\van Lingen et al. - 2019 - Prediction of enteric methane production, yield an.pdf}
}

@article{sjaunja1990NordicProposalEnergy,
  title = {A {{Nordic}} Proposal for an Energy Corrected Milk ({{ECM}}) Formula},
  author = {Sjaunja, L.O. and Baevre, L. and Junkkarinen, L. and Pedersen, Jørn},
  date = {1990-01-01},
  journaltitle = {27th Session of ICRPMA},
  shortjournal = {27th Session of ICRPMA},
  pages = {156--157},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\S\Sjaunja et al_1990_A Nordic proposal for an energy corrected milk (ECM) formula.pdf}
}

@article{zhang2023MethanePredictionEquationsa,
  title = {Methane Prediction Equations Including Genera of Rumen Bacteria as Predictor Variables Improve Prediction Accuracy},
  author = {Zhang, Boyang and Lin, Shili and Moraes, Luis and Firkins, Jeffrey and Hristov, Alexander N. and Kebreab, Ermias and Janssen, Peter H. and Bannink, André and Bayat, Alireza R. and Crompton, Les A. and Dijkstra, Jan and Eugène, Maguy A. and Kreuzer, Michael and McGee, Mark and Reynolds, Christopher K. and Schwarm, Angela and Yáñez-Ruiz, David R. and Yu, Zhongtang},
  date = {2023-12-02},
  journaltitle = {Scientific Reports},
  shortjournal = {Sci Rep},
  volume = {13},
  number = {1},
  pages = {21305},
  publisher = {Nature Publishing Group},
  issn = {2045-2322},
  doi = {10.1038/s41598-023-48449-y},
  url = {https://www.nature.com/articles/s41598-023-48449-y},
  urldate = {2024-08-20},
  abstract = {Methane (CH4) emissions from ruminants are of a significant environmental concern, necessitating accurate prediction for emission inventories. Existing models rely solely on dietary and host animal-related data, ignoring the predicting power of rumen microbiota, the source of CH4. To address this limitation, we developed novel CH4 prediction models incorporating rumen microbes as predictors, alongside animal- and feed-related predictors using four statistical/machine learning (ML) methods. These include random forest combined with boosting (RF-B), least absolute shrinkage and selection operator (LASSO), generalized linear mixed model with LASSO (glmmLasso), and smoothly clipped absolute deviation (SCAD) implemented on linear mixed models. With a sheep dataset (218 observations) of both animal data and rumen microbiota data (relative sequence abundance of 330 genera of rumen bacteria, archaea, protozoa, and fungi), we developed linear mixed models to predict CH4 production (g CH4/animal·d, ANIM-B models) and CH4 yield (g CH4/kg of dry matter intake, DMI-B models). We also developed models solely based on animal-related data. Prediction performance was evaluated 200 times with random data splits, while fitting performance was assessed without data splitting. The inclusion of microbial predictors improved the models, as indicated by decreased root mean square prediction error (RMSPE) and mean absolute error (MAE), and increased Lin’s concordance correlation coefficient (CCC). Both glmmLasso and SCAD reduced the Akaike information criterion (AIC) and Bayesian information criterion (BIC) for both the ANIM-B and the DMI-B models, while the other two ML methods had mixed outcomes. By balancing prediction performance and fitting performance, we obtained one ANIM-B model (containing 10 genera of bacteria and 3 animal data) fitted using glmmLasso and one DMI-B model (5 genera of bacteria and 1 animal datum) fitted using SCAD. This study highlights the importance of incorporating rumen microbiota data in CH4 prediction models to enhance accuracy and robustness. Additionally, ML methods facilitate the selection of microbial predictors from high-dimensional metataxonomic data of the rumen microbiota without overfitting. Moreover, the identified microbial predictors can serve as biomarkers of CH4 emissions from sheep, providing valuable insights for future research and mitigation strategies.},
  langid = {english},
  file = {C:\Users\858782\OneDrive - DSM\Documents\08_Zot\Z\Zhang et al_2023_Methane prediction equations including genera of rumen bacteria as predictor2.pdf}
}

@article{mcginn2021TechnicalNoteValidation,
  title = {Technical Note: Validation of the {{GreenFeed}} System for Measuring Enteric Gas Emissions from Cattle},
  shorttitle = {Technical Note},
  author = {McGinn, Sean M and Coulombe, Jean-Franҫois and Beauchemin, Karen A},
  date = {2021-03-01},
  journaltitle = {Journal of Animal Science},
  volume = {99},
  number = {3},
  pages = {skab046},
  issn = {0021-8812, 1525-3163},
  doi = {10.1093/jas/skab046},
  url = {https://academic.oup.com/jas/article/doi/10.1093/jas/skab046/6149109},
  urldate = {2024-08-29},
  abstract = {Abstract             There are knowledge gaps in animal agriculture on how to best mitigate greenhouse gas emissions while maintaining animal productivity. One reason for these gaps is the uncertainties associated with methods used to derive emission rates. This study compared emission rates of methane (CH4) and carbon dioxide (CO2) measured by a commercially available GreenFeed (GF) system with those from (1) a mass flow controller (MFC) that released known quantities of gas over time (i.e., emission rate) and (2) a respiration chamber (RC). The GF and MFC differed by only 1\% for CH4 (P = 0.726) and 3\% for CO2 (P = 0.013). The difference between the GF and RC was 1\% (P = 0.019) for CH4 and 2\% for CO2 (P = 0.007). Further investigation revealed that the difference in emission rate for CO2 was due to a small systematic offset error indicating a correction factor could be applied. We conclude that the GF system accurately estimated enteric CH4 and CO2 emission rates of cattle over a short measurement period, but additional factors would need to be considered in determining the 24-hr emission rate of an animal.},
  langid = {english},
  file = {C:\Users\858782\Zotero\storage\X4ISVH8W\McGinn et al. - 2021 - Technical note validation of the GreenFeed system.pdf}
}
